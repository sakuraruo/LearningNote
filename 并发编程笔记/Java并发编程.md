## 一、可见性、原子性和有序性问题：并发编程Bug的源头

1.这些年CPU、内存、I/O设备在不断迭代，速度在不断提升，但是一个锚段一直存在，就是这三者的速度差异。为了合理利用CPU的高性能，平衡这三者的速度差异，计算机体系结构、操作系统、编译程序都做出了贡献。

1）CPU增加了缓存，以均衡与内存的速度差异；

2）操作系统增加了进程、线程，以分时复用CPU。进而均衡CPU与IO设备的速度差异；

3）编译程序优化指令执行次序，使得缓存能够得到更加合理地利用；

2.源头之一：缓存导致的可见性问题

在单核时代，所有的线程都是在一颗CPU上执行，CPU缓存与内存的缓存一致性容易解决。因为所有线程都是操作同一个CPU的缓存，一个线程对缓存的写，对于另外一个线程来说一定是可见的。

一个线程对共享变量的修改，另外一个线程能够立刻看到，我们称为"可见性"。

多核时代，每颗CPU都有自己的缓存，这时CPU缓存与内存的数据一致性就没那么容易解决了，当多个线程在不同的CPU上执行时，这些线程操作的是不同的CPU缓存。

3.源头之二：线程切换带来的原子性问题

例如：高级语言中的count+=1，至少需要三条CPU指令

指令1：首先，需要把变量count从内存加载到CPU的寄存器

指令2：之后，在寄存器中执行+1操作；

指令3：最后，将结果写入内存(缓存机制导致可能写入的是CPU缓存而不是内存)。

我们把一个或者多个操作在CPU执行的过程中不被中断的特性称为原子性。

4.源头之三：编译优化带来的有序性问题

编译器为了优化性能，有时候会改变程序中语句的先后顺序，例如程序中："a=6;b=7",编译器优化后可能变成"b=7；a=6;",在这个例子中，编译器调整了语句的顺序，但是不影响程序的最终结果。

在Java领域一个经典的案例就是利用双重检查创建单例对象，但其实这个getInstance方法并不完美。问题出在new操作上，我们以为的new操作应该是：

1）分配一块内存M；

2）在内存M上初始化Singleton对象；

3）然后M的地址赋值给instance变量；

但是实际上优化后的执行路径却是这样的：

1)分配一块内存M；

2)将M的地址赋值给instance变量；

3）在内存M上初始化Singleton对象；

这就有可能因为顺序问题，导致instance触发空指针异常。



## 二、Java内存模型：看Java如何解决可见性和有序性的问题

1.导致可见性的原因是缓存，导致有序性的原因是编译优化，那解决可见性、有序性最直接的办法就是禁用缓存和编译优化，但是这样问题虽然解决了，我们程序的性能可就堪忧了。合理的方案应该是按需禁用缓存及编译优化。Java内存模型是个很复杂的规范，可以从不同的视角来解读，站在我们这些程序员的视角，本质上可以理解为，Java内存模型规范了JVM如何提供按需禁用缓存和编译优化的方法。具体来说，这些方法包括了volatile、synchronized和final三个关键字，以及六项happens-before规则。

2.Happens-Before规则，并不是说前面一个操作发生在后续操作的前面，它真正要表达的是：前面一个操作的结果对后续操作是可见的。

1）程序的顺序性规则：这条规则是指在一个线程中，按照顺序操作，前面的操作Happens-Before于后续的任意操作。

2）volatile变量规则：这条规则是指对一个volatile变量的写操作，Happens-Before于后续对这个volatile变量的操作。

3）传递性：这条规则是指如何A happens-Before B，且B happens C，那么A happens-Before C。

3.管程中锁的规则：这条规则是指对一个锁的解锁Happens-Befoe于后续对这个锁的加锁。

什么是"管程"。管程是一种通用的同步原语，在Java中指的是Synchronized,Synchronized是Java里对管程的实现。管程中的锁在Java里是隐式实现的，是由编译器实现的。

4.线程start()规则

这条是关于线程启动的。它是指主线程A启动子线程B后，子线程B能够看到主线程在启动子线程B前的操作。换句话说就是，如果线程A调用线程B的start方法，那么就该start操作Happens-Before于线程B中的任意操作。

5.线程join规则

这条是关于线程等待的。它是指主线程A等待子线程B完成(主线程A通过调用子线程B的join方法实现)，当子线程B完成后(主线程A中join方法返回)，主线程能够看到子线程的操作。

6.被我们忽视的final

volatile为的是禁用缓存以及编译优化，我们再从另外一个方面来看，有没有办法告诉编译器优化得更好一点呢？这个可以又，就是final关键字。

final修饰变量时，初衷是告诉编译器：这个变量生而不变，可以可劲儿优化。Java编译器在1.5以前的版本的确优化得很努力了，以至于都优化错了。问题类似于双重检查方法创建单例，构造函数的重排序导致线程可能看到final变量的值会变化。

JDK1.5之后对Java内存模型对final类型的重排进行了约束。现在只要我们提供正确构造函数没有""逸出"，就不会出问题了。"逸出"有点抽象，我们还是举个例子吧，在构造函数中将this赋值给了全局变量，线程通过全局变量读取x可能读取到0，所以要避免"逸出"。

7.线程中断规则：对线程interrupt方法的调用先行发生于被中断线程的代码检测到中断事件的发生，可以通过Thread.interrupt方法检测到是否有中断发生。

8.线程终结规则：一个对象的初始化完成(构造函数执行结束)先行发生于它的finalize方法的开始。



## 三、互斥锁(上):解决原子性问题

1.原子性的源头是线程切换，如果能够禁用线程切换，那不就能解决这个问题了吗？而操作系统做线程切换时是依赖CPU中断的，所以如果禁用CPU中断就能够禁止线程切换。

在单核CPU场景下，同一时刻只有一个线程执行，禁止CPU中断，意味着操作系统不会重新调度线程，也就是禁止了线程切换，获得CPU使用权的线程就可以不间断地执行，所以两次写操作就具有原子性。

但是在多核场景下，同一时刻，有可能两个线程同时在执行，一个线程执行在CPU-1上，一个线程执行在CPU-2上，此时禁止CPU中断，只能保证CPU上的线程连续执行，并不能保证同一时刻，如果这两个线程同时写long型变量高32位的话，那就有可能出现我们开头提及的诡异bug了。

"同一时刻只有一个线程执行"这个条件非常重要，我们称之为互斥。如果我们能够保证对于共享变量的修改是互斥的，那么无论是单核还是多核CPU，都能保证原子性。

2.简易锁模型

当谈到互斥，就会想到锁。我们把一段需要互斥执行的代码称为临界区。线程在进入临界区之前，首先尝试加锁lock()，如果成功，则进入临界区，此时我们称这个线程持有锁；否则就等待，直到持有锁的线程解锁；持有锁的线程执行完临界区的代码后，执行解锁unlock()

改进后的锁模型

在并发编程世界里，锁和资源也应该有关系。如图：

![image-20211124222403727](pic\image-20211124222403727.png)

在临界区中增加了一个元素：受保护的资源R；其次，我们要保护资源R就得为它创建一把锁LR；最后，针对这把锁LR，我们还需在进出临界区时添上加锁操作和解锁操作。

3.Java语言提供的锁技术：synchronized

当修饰静态方法的时候，锁定的是当前类的Class对象，在上面的例子中就是Class X；当修饰非静态方法的时候，锁定的是当前实例对象this。



## 四、互斥锁（下）：如何用一把锁保护多个资源？

1.用不同的锁对受保护资源进行精细化管理，能够提升性能，这种锁还有个名字。叫细粒度锁。

2.“原子性”的本质是什么？其实不是不可分割，不可分割只是外在表现，其本质是多个资源间有一致性要求，操作的中间状态对外不可见。例如，在32位的机器上写long类型变量有中间状态，在银行转账的操作中也有中间状态(账户A减少了100，账户B还没来得及发生变化)。所以解决原子性问题，是要保证中间状态对外不可见。



## 五、 一不小心就死锁了，怎么办？

1.细粒度锁。使用细粒度锁可以提高并行度，是性能优化的重要手段。的确，使用细粒度锁是有代价的，这个代价就是可能会导致死锁。

2.死锁的一个比较专业的定义是：一组互相竞争资源的线程因为相互等待，导致“永久”阻塞现象。

3.如何预防死锁。并非法程序一旦死锁，一般没有特别好的方法，很多时候我们只能重启应用。因此，解决死锁问题最好的办法还是规避死锁。

那如何规避死锁呢？要避免死锁就需要分析死锁发生的条件，有个叫Cofffman的牛人早就总结过了，只有以下这四个条件都发生时才会出现死锁：

1）互斥，共享资源X和Y只能被一个线程占用；

2）占有且等待，线程T1已经取得共享资源X，在等待共享资源Y的时候，不释放共享资源X；

3）不可抢占，其他线程不能强行抢占线程T1占有的资源。

4）循环等待，线程T1等待T2占有的资源，线程T2等待线程T1占有的资源，就是循环等待。

也就是说只要我们破坏其中一个，就可以避免死锁的发生。

4.破坏占用且等待条件

从理论上讲，要破坏这个条件，可以一次性申请所有资源。

5.破坏不可抢占条件

破坏不可抢占条件看上去很简单，核心时要能够主动释放它占有的资源，这一点synchronized时做不到的。原因时synchronized申请资源的时候，如果申请不到，线程直接进入阻塞状态了，而线程进入阻塞状态，啥都干不了，也释放不了线程已经占有的资源。

6.破坏循环等待条件

破坏这个条件，需要对资源进行排序，然后按序申请资源。这个实现非常简单，我们假设每个账户都有不同的属性id，这个id可以作为排序字段，申请的时候，我们可以按照从小到大的顺序来申请。



## 六、用“等待-通知”机制优化循环等待

1.在破坏占用且等待条件的时候，如果转出账本和转入账本不满足同时在文件架上这个条件，就用死循环的方式来循环等待。

![image-20211124234224561](pic\image-20211124234224561.png)

如果apply操作耗时非常短，而且并发冲突量也不大时，这个方案还挺不错的，因为这个场景下，循环上几次或者几十次就能一次性获取转入账户和转入账户了。但是如果apply操作耗时长，或者并发冲突量大的时候，循环等待这种方案就不适用了，因为在这种场景下，可能要循环上万次才能获取到锁，太消耗CPU了。

其实在这种场景下，最好的方案应该是：如果线程要求的条件(转出账本和转入账本同在文件夹上)不满足，则线程阻塞自己，进入等待状态；当线程要求的条件(转出账本和转入账本同在文件架上)满足后，通知等待的线程重新执行。其中使用线程阻塞的方式就能避免循环等待消耗CPU的问题。

2.用synchronized实现等待-通知机制

在Java语言里，等待-通知机制可以有多种实现方式，比如Java语言内置的synchronized配合wait()、notify()、notifyAll()这三个方法就能轻松实现。

如何用synchronized实现互斥锁，你 应该已经很熟悉了。在下面这个图里，左边有一个等待队列，同一时刻，只允许一个线程进入synchronized保护的临界区(这个临界区可以看作大夫的诊室)，当有一个线程进入临界区后，其他线程就只能进入图中左边的等待队列里等待(相当于患者分诊等待)。这个等待队列和互斥锁是一对一关系，每个互斥锁都有自己独立的等待队列。

![image-20211124235416500](pic\image-20211124235416500.png)

在并发程序中，当一个线程进入临界区后，由于某些条件不满足，需要进入等待状态，Java对象的wait()方法就能满足这种需求。如上图所示，当调用wait()方法后，当前线程就会被阻塞，并且进入到右边的等待队列中，这个等待队列也是互斥锁的等待队列。线程在进入等待队列的同时，会释放持有的互斥锁，线程释放锁后，其他线程就有机会获得锁，并进入临界区了。

那线程要求的条件满足时，该怎么通知这个等待的线程呢？很简单，就是Java对象的notify()和notifyAll()方法。我在下面这个图里为你大致描述了这个过程，当条件满足时调用notify(),会通知等待队列(互斥锁的等待队列)中的线程，告诉它条件曾经满足过。

![image-20211125000429764](pic\image-20211125000429764.png)

为什么说是曾经满足过呢？因为notify()只能保证在通知时间点，条件是满足的。而被通知线程的执行时间点和通知的时间点基本不会重合，所以当线程执行的时候，很可能条件已经不满足了(保不齐有其他线程插队)。**这一点需要格外注意**。

除此之外，还有一个需要注意的点，被通知的线程要想重新执行，仍然需要获取到互斥锁(因为曾经获取的锁在调用wait()时已经释放了)。

上面我们一直强调wait()、notify()、notifyAll()方法操作的等待队列时互斥锁的等待队列，所以如果synchronized锁定的是this，那么对应的一定是this.wait()、this.notify()、this.notifyAll();如果synchronized锁定的是target，那么对应的一定是target.wait()、target.notify()、target.notifyAll()。而且wait()、notify()、notifyAll()这三个方法发能够被调用的前提一定是已经获取了对应的互斥锁，所以我们会发现这三个方法都是在synchronized内部被调用的。如果在synchronized外部调用，或者锁定的this，而用target.wait调用的话，JVM会抛出Java.lang.IllegalMonitorStateException。

基于这个上篇中，就可以让获取到锁的对象去进入阻塞态而非循环等待。
