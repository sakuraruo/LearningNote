## 一、基础机构:一个键值数据库包含什么？	

1.不同键值数据库支持的key类型一般差异不大，而value类型则有较大差异。对于键值数据库进行选型时，一个重要的考虑因素就是它支持的value类型。例如memcached支持的value类型仅为String类型，而redis支持的value包括了string、hash、列表、集合等。Redis能够在实际业务场景中得到广泛应用，就是得益于支持多样化类型的value。

2.键值数据库需要支持的三种基本操作：即PUT(写入)、GET(获取)和DELETE(删除)。有些键值数据库的新写/更新操作叫set。在实际的业务场景中，我们经常会遇到这种情况：查询一个用户在一段时间内的访问记录。这种操作在键值数据库中数据SCAN操作，即根据一段key的范围返回相应的value值。因此，PUT、GET、DELETE、SCAN是一个键值数据库的基本操作集合。

3.键值数据库的键值对是保存在内存还是外存呢？

进行设计选择，我们通常需要考虑键值数据库的主要应用场景。比如，缓存场景下的数据需要能快速访问但允许丢失，那么用于此场景的键值数据库通常采用内存保存键值数据。

4.一个键值数据库包括了访问框架、索引模块、操作模块和存储模块四部分。

![image-20211027143901498](pic\image-20211027143901498.png)

5.什么是访问模式？

访问模式通常有两种：一种是通过函数库调用方式供外部应用调用，比如通过动态链接库的形式链接到我们自己的程序中，提供键值存储功能；另外一种是通过网络框架以Socket通信的形式对外提供键值对操作，这种形式可以提供广泛的键值存储服务。

通过网络框架提供键值存储服务，一方面扩大了键值数据库的受用面，但另一方面，要给键值数据库的性能、运行模型提供了不同的设计选择，带来了一些潜在的问题。简单来说，就是网络连接的处理、网络请求的解析，以及数据存取的处理，是用一个线程、多个线程，还是多个进程来交互处理呢？该如何进行设计和取舍呢？我们把这个问题成为I/O模型设计。不同的I/O模型对键值数据库的性能和可扩展性会有不同影响。

举个例子，如果一个线程既要处理网络请求、解析请求、又要完成数据存取，一旦某一步操作发生阻塞，整个线程就会阻塞住，这就降低了系统响应速度。如果我们采用不同线程处理不同操作，那么某个线程阻塞住时，其他线程还能正常运行。但是不同线程之间如果需要访问共享资源，又会产生线程竞争，也会影响系统效率，这又该怎么办呢？

6.如何定位键值对的位置？

键值数据库需要查找所要的键值对是否存在，这依赖于键值数据库的索引模块。索引的作用是让键值数据库根据key找到相应value的存储位置，进而执行操作。

不同的索引结构在性能、空间消耗、并发控制等方面具有不同的特征。一般而言，内存键值数据库采用hash作为索引，很大一部分原因在于键值数据基本都是保存在内存中的，而内存的高性能随机访问可以很好地与hash O(1)的时间复杂度相匹配。对于redis而言，它的value支持多种类型，当我们通过索引找到一个jey所对应的value后，仍然需要从value的复杂结构中进一步找到我们实际需要的数据，这个操作的效率本身就依赖于它们的实现结构。Redis采用一些常见的高效索引结构作为某些value类型的底层数据结构，这一技术路线为Redis实现高性能访问提供了良好的支撑。

7.不同操作的具体逻辑是怎样的？

键值数据库的索引模块负责根据key找到相应的value的存储位置。对于不同的操作来说，找到存储位置之后，需要进一步执行的操作的具体逻辑会有差异。

1）对于Get/Scan操作而言，此时根据value的存储位置返回value即可。

2）对于PUT一个新的键值对数据而言，键值数据库需要为其分配内存空间。

3）对于delete操作，键值对数据库需要删除键值对，并释放相应的内存空间，这个过程由分配器完成。

这些操作需要分配和释放内存，这就不得不提到存储模块了。

8.如何实现重启后快速提供服务？

键值数据库采用了常用的内存分配器glib的malloc和free，因此键值数据库并不需要特别考虑内存空间的管理问题。但是键值数据库 键值对通常大小不一，glib的分配器在处理随机的大小内存块分配时，表现并不好。一旦保存的键值对数据规模过大，就可能会导致较严重的内存碎片问题。分配器是键值数据库中的一个关键因素。Redis的内存分配器提供了多种选择，分配效率也不一样，后面会具体讲一讲。

键值数据库虽然依赖于内存保存数据，提供快速访问。但是希望重启后，仍然能够快速提供服务，所以需要存储模块增加持久化功能。

9.为了支持更加丰富的业务场景，Redis对这些组件或者功能进行了扩展，或者说是进行了精细优化，从而满足了功能和性能等方面的需求。

![image-20211027152820283](pic\image-20211027152820283.png)

1)redis主要通过网络框架进行访问，这使得redis可以作为一个基础性的网络服务进行访问，扩大了redis的应用范围。

2）Redis数据模型中的value类型很丰富，因此也带来了更多的操作接口，例如面向列表的LPUSH/LPOP，面向集合的SADD/SREM等。

3）Redis的持久化模块能支持两种方式：日志(AOF)和快照(RDB)，这两种持久化方式具有不同的优劣势，影响到Redis的访问性能和可靠性。

4）Redis支持高可用集群和高扩展集群。因此Redis中包含了相应的集群功能支撑模块。



## 二、快速的Redis有哪些慢操作？

1.说到Redis快，有一个重要的表现：它接收到一个键值对操作后，能以微秒级别的速度找到数据，并快速完成操作。

2.String、List、Hash、Set和Sorted Set,这些只是Redis键值对中的数据类型，也就是数据的保存形式。所谓的Redis数据结构，指的是底层实现。

3.Redis底层数据结构一共有6种，分别是"简单动态字符串"、"双向链表"、"压缩列表"、"hash表"、"跳表"、"整数数组"。

4.Redis数据类型和底层数据结构的对应关系。

1）String => 简单动态字符串

2）List => 双向链表、压缩列表

3）Hash => 压缩列表、hash表

4）Sorted Set =>跳表

5）Set =>整数数组

5.除了String外，redis的其他数据类型List、hash、set、sorted set都被称为集合类型。

6.键和值用什么结构组织？

为了实现从key到value的快速访问，Redis使用了一个hash表来保存所有键值对。

但是，如果你只是了解了hash表的O(1)复杂度和快速查找特性，那么当你往Redis中写入大量数据后，就可能发现操作有时候会突然变慢了。这是因为你忽略了一个潜在的风险，那就是hash表的冲突问题和rehash可能带来的操作阻塞。

7.为什么hash表操作变慢了？

hash表当发生hash冲突时，会生成一条"hash冲突链"，当写入的数据越来越多，hash冲突可能也会越来越多，这就导致了冲突链过长，影响查找性能。所以Redis会对hash表做rehash操作。rehash也就是增加现有的hash桶数量，让逐渐增多的entry元素能在更多的桶之间分散保存，减少单个桶中的元素数量，从而减少单个桶的冲突。

redis为了使rehash更加高效，redis默认使用了两个全局hash表：hash表1和hash表2。一开始，当你插入数据时，默认使用hash表1，此时hash表2并没有分配空间，随着数据增多，redis开始rehash，这个过程分3步。

1）给hash表2分配更大的空间，例如是当前hash表1的两倍。

2）把hash表1的数据重新映射并拷贝到hash表2。

3）释放hash表1的空间

这时候请求数据从hash表1切换到hash表2，hash表1作为下次扩容用，而在拷贝过程中，会造成redis线程阻塞，无法服务其他请求，所以redis就无法快速访问数据了。

8.为了解决rehash导致的阻塞问题，redis采用了渐进式rehash。

简单来说，就是在第二步拷贝数据时，redis仍然正常处理客户端请求，每处理一个请求时，从hash表1中的第一个索引位置开始，顺带着将这个索引位置上的所有entries拷贝到hash表2中；等处理下一个请求时，再顺带拷贝hash表1中的下一个索引位置的entries。如下图所示：

![image-20211027161400574](pic\image-20211027161400574.png)

这样就巧妙地把一次性大量拷贝的开销，分摊到了多次处理请求的过程中，避免了耗时操作，保证了数据的快速访问。

9.有哪些底层数据结构？

1）hash表，操作时间复杂度为O(1)。

2）整数数组和双向列表，它们的操作都是顺序读写，时间复杂度为O(n)。

3）压缩列表实际上类似于一个数组，数组中的每一个元素都对应保存一个数据。和数组不同的是，压缩列表在表头有三个字段zlbytes、zltail和zllen，分别表示列表长度、列表尾的偏移量和列表中的entry个数；压缩列表在表尾还有一个zlend，表示列表结束。

![image-20211027163135057](pic\image-20211027163135057.png)

在压缩列表中，如果我们要查找定位第一个元素和最后一个元素，可以通过表头三个字段长度直接定位，复杂度是O(1)。而查找其他元素时，就没那么高效了，复杂度为O(n)。

4）跳表

有序列表只能逐一查找元素，导致操作起来非常缓慢，于是出现了跳表。具体来说，跳表在链表的基础上，增加了多级索引，通过索引位置的几个跳转，实现数据的快速定位。

![image-20211027163437390](pic\image-20211027163437390.png)

根据时间复杂度对这些数据结构进行分类：

![image-20211027163705781](pic\image-20211027163705781.png)

10.不同操作的复杂度

集合类型的操作类型很多，有读写单个集合元素的，例如HGET、HSET，也有操作多个元素的，例如SADD，还有对整个集合进行遍历操作的，例如SMEMBRS。通过口诀，快速记住各种操作的复杂度。

1）单元素操作是基础

第一，单元素操作，是指每一种集合类型对单个数据实现的增删改查操作。例如，hash类型的HGET、HSET、HDEL，SET类型的SADD、SREM、SRANDMEMBER等。这些操作的复杂度由集合采用的数据结构决定，例如，HGET、HSET和HDEL是对hash表做操作，所以它们的复杂度都是O(1)；Set类型用hash表作为底层数据结构时，它的SADD、SREM、SRANDMEMBER复杂度都是O(1)。

这里有个地方需要注意一下，集合类型支持同时对多个元素进行增删改查，例如Hash类型的HMGET和HMSET，Set类型的SADD也支持同时增加多个元素。这时候操作的复杂度，就由单个元素操作复杂度和元素个数决定的。

2）范围操作非常耗时

第二，范围操作，是指几个类型中的遍历操作，可以返回集合中的所有数据，比如hash类型的HGETALL和SET类型的SMEMBERS，或者返回一个范围内的部分数据，比如List类型的LRANGE和ZSET类型的ZRANGE。这类操作的复杂度一般是O(n)，比较耗时，我们应该尽量避免。

不过redis从2.8版本开始提供了SCAN系列操作(包括HSCAN、SSCAN和ZSCAN)，这类操作实现了渐进式遍历，每次只返回有限数量的数据这样一来，相比于HGETALL、SMEMBERS这类操作，就避免了一次性返回所有元素而导致的Rdis阻塞。

3）统计操作通常高效

第三、统计操作，是指集合类型对集合中的所有元素个数的记录，例如LLEN和SCARD。这类操作复杂度只有O(1)，这是因为当集合类型采用压缩列表、双向链表、整数数组这些数据结构时，这些结构专门记录了元素个数的统计，因此可以高效完成相关操作。

4）例外情况只有几个

第四，例外情况，是指某些数据结构的特殊记录，例如压缩列表和双向链表都会记录表头和表尾的偏移量。这样一来，对于List类型的LPOP、RPOP、LPUSH、RPUSH这四个操作来说，它们是在列表的头尾增删元素，这就可以通过偏移量直接定位，所以它们的复杂度也只有O(1)。



## 三、高性能IO模型：为什么单线程Redis能那么快？

1.Redis是单线程的，主要是指Redis的网络IO和键值对读写是由一个线程来完成的，这也是Redis对外提供键值存储服务的主要流程。但Redis的其他功能，比如持久化、异步删除、集群数据同步等，其实是由额外的线程执行的。

2.Redis为什么用单线程？

首先了解多线程的开销。日常写程序时，我们经常会听到一种说法，"使用多线程，可以增加系统吞吐率，或是可以增阿基系统扩展性"。的确，对于一个多线程的系统来说，在有合理的资源分配的情况下，可以增加系统中处理请求操作的资源实体，进而提升系统能够同时处理的请求数，即吞吐率。但是如果使用多线程，在没有良好的系统设计，实际得到的结果，增加线程并不一定会增长吞吐率，甚至有可能还会下降。

为什么会出现这种情况呢？一个关键的瓶颈在于，系统通常会存在被多线程同时访问的共享资源，比如一个共享的数据结构。当有多个线程要修改这个共享资源时，为了保证共享资源的正确性，就需要有额外的机制来保证。而这额外的机制，就会带来额外的开销。

并发发访问控制一直是多线程开发中的一个难点问题，如果没有精细的设计，比如说，只是简单地采用一个粗粒度互斥锁，就会出现不理想的结果：即使增加了线程，大部分线程也在等待获取共享资源的互斥锁，并行变串行，系统吞吐率并没有随着线程的增加而增加。而且，采用多线程开发一般会引入同步原语来保护共享资源的并发访问，这也会降低系统代码的易调试性和可维护性，为了避免这些问题，Redis直接采用了单线程模式。

3.单线程Redis为什么那么快？

通常来说，单线程的处理能力要比多线程差很多，但是Redis却能使用单线程模型达到每秒数十万级别的处理能力，这是为什么呢？其实，这是Redis多方面设计选择的一个综合结果。

一方面，Redis的大部分操作在内存上完成，再加上它采用了高效的数据结构，例如hash表和跳表，这是它实现高性能的一个重要原因。另外一方面，就是Redis采用了多路复用机制，使其在网络IO操作中能并发处理大量的客户端请求，实现吞吐率。

4.网络操作的基本IO模型和潜在阻塞点。

以GET请求为例，为了处理一个GET请求，需要监听客户端请求(bind、Listener),和客户端建立连接(accept)，从socket中读取请求(recv)，解析客户端发送请求(parse)，根据请求类型读取键值数据(get),最后给客户端返回结果，即向socket中写回数据。

![image-20211027231302631](pic\image-20211027231302631.png)

在这里的网络IO操作中，有潜在的阻塞点，分别是accept()和recv()。当Redis监听到一个客户端有连接请求，但一直未能成功建立起连接时，会阻塞在accept()函数这里，导致其他客户端无法和Redis建立连接。类似的，当Redis通过Recv()从一个客户端读取数据时，如果数据一直没有到达，Redis也会一直阻塞在recv()。

这就导致Redis整个线程阻塞，无法处理其他客户端请求，效率很低。不过幸运的是，socket网络模型本身支持非阻塞模式。

5.非阻塞模式

在socket模型中，不同操作调用后会返回不同的套接字类型。socket()方法会返回套接字，然后调用listen()方法，将主动套接字转化为监听套接字，此时，可以监听来自客户端的连接请求。最后调用accept()方法接收到达的客户端连接，并且返回已连接套接字。

![image-20211027232441483](pic\image-20211027232441483.png)

针对监听套接字，我们可以设置非阻塞模式，当Redis调用accept() 但一直未有连接请求到达时，Redis线程可以返回处理其他操作，而不用一直等待。但是你要注意的是，调用accept()时，已经存在监听套接字了。虽然Redis线程可以不用继续等待，但是总得有机制继续在监听套接字上等待后续连接请求，并在有请求时通知Redis。类似的，我们也可以针对已连接套接字设置非阻塞模式：Redis调用recv()后，如果已连接套接字上一直没有数据到达，Redis线程同样可以返回处理其他操作。我们也需要有机制继续监听该已连接套接字，并在有数据到达时通知Redis。这样才能保证Redis线程，既不会像基本IO模型中一直在阻塞点等待，也不会导致Redis无法处理实际到达的连接请求或数据。

6.基于多路复用的高性能IO模型

Linux中的IO多路复用机制是指一个线程处理多个IO流，就是我们经常听到的select/epoll机制。简单来说，在Redis只运行单线程的情况下，该机制允许内核中，同事存在多个监听套接字和已连接套接字。内核会一直监听这些套接字上的连接请求或数据请求。一旦有请求到达就交给Redis线程处理，这实现了一个Redis线程处理多个IO流的效果。

下图就是基于多路复用的Redis IO模型。图中的多个FD就是刚才所说的多个套接字。Redis网络框架调用epoll机制，让内核监听这些套接字 。此时，Redis线程不会阻塞在某一个特定的监听或已连接套接字上，也就是说，不会阻塞在某一个特定的客户端连接处理。正因为如此，Redis可以同时和多个客户端连接并处理请求，从而提升并发性。

![image-20211027235918862](pic\image-20211027235918862.png)

为了在请求到达时能通知到Redis线程，select/epoll提供了基于事件的回调机制，即针对不同事件的发生，调用相应的处理函数。

那么回调机制是怎么工作的呢？其实select/epoll一旦检测到FD上有请求到达时，就会触发相应的事件。这些事件会被放进一个事件队列，redis单线程对该时间队列不断进行处理。这样一来，Redis无需一直轮训是否有请求实际福发盛，这就可以避免曹成CPU资源浪费。同时，Redis在对事件队列进行处理时，会调用相应的处理函数，这就实现了基于事件的回调。因为Redis一直在对事件队列进行处理，所以能及时相应客户端请求，提升了Redis的响应性能。

以连接请求和读数据请求为例。这两个请求分别对应Accept事件和Read事件，Redis分别对着两个事件注册accept和get回调函数。当linux内核监听到有连接请求或读数据请求时，就会触发Accept事件和Read事件，此时，内核就会回调Redis相应的accept和get函数进行处理。

Redis单线程发处理IO请求性能瓶颈主要包括2个方面：

1.任意一个请求在server中一旦发生耗时，都会影响整个server的性能，也就是说后面的请求都要等前面这个耗时请求处理完成，自己才能被处理到。耗时的操作包括以下几种：

a.操作bigkey：写入一个bigkey在分配内存时需要消耗更多的时间，同样，删除bigkey释放内存同样产生耗时。

b.使用复杂度过高的命令：例如SORT/SUNION/ZUNIONSTORE,或者O(n)命令，但是N很大，例如lrange key 0 -1一次查询全量数据。

c.大量key集中过期：Redis的过期机制也是在主线程中执行的，大量key集中过期会导致处理一个请求时，耗时都在删除过期key，耗时变长。

d.淘汰策略：淘汰策略也是在主线程中执行的，当内存超过Redis上限后，每次写入都需要淘汰一些key，也会导致耗时变长。

e.AOF刷盘开启always机制，每次写入都需要把这个操作刷到磁盘，写磁盘的速度远比写内存慢，会拖慢Redis性能。

f.主从全量同步生成RDB，虽然采用fork子进程生成数据快照，但fork这一瞬间会阻塞整个线程的，实例越大，阻塞时间越长。



2.并发量很大时，单线程读写客户端IO数据存在性能瓶颈，虽然采用IO多路复用机制，但是读写客户端数据依旧是同步IO，只能单线程依次读取客户端的数据，无法利用到CPU多核。

针对问题1，一方面需要业务人员去规避，一方面Redis在4.0退出了lazy-free机制，把bigkey释放内存的耗时操作放在了异步线程中执行，降低了对主线程的影响。

针对问题2，Redis在6.0推出了多线程，可以在高并发场景下利用CPU多核多线程读写客户端数据，进一步提升server性能，当然，只是针对客户端的读写是并行的，每个命令的执行依旧是单线程的。



## 四、AOF日志：宕机了，Redis如何避免数据丢失？

1.Redis不可忽略性的问题：一旦服务器宕机，内存中的数据将全部丢失。

2.Redis的持久化主要有两大机制，即AOF(Append only File)日志和RDB快照。

3.AOF日志是如何实现的？

说到日志，我们比较熟悉的是数据库的写前日志(write ahead log，WAL),也就是说，在实际写数据前，先把修改的数据记到日志文件中，以便故障时进行恢复。不过AOF日志正好相反，它是写后日志，"写后"的意思是Redis是先执行命令，把数据写入内存，然后才记录日志，如下图所示：

![image-20211028092654791](pic\image-20211028092654791.png)

4.AOF为什么要先执行命令再记日志呢？要回答这个问题，我们要先知道AOF里记录了什么内容。传统数据库的日志，例如redo log(重做日志)，记录的是修改后的数据，而AOF里记录的是Redis收到的每一条命令，这些命令是以文本形式保存的。为了避免额外的检查开销，Redis在向AOF里面记录日志的时候，并不会先去对这些命令进行语法检查。所以，如果先记日志再执行命令的话，日志中就有可能记录了错误的命令，Redis在使用日志恢复数据时，就可能出错。Redis的写后日志这种设计就能很好地避免出错命令问题。除此之外，AOF还有一个好处：它是在命令执行后才记录日志，所以不会阻塞当前的写操作。

不过AOF也有两个潜在的风险。

1）首先，如果刚执行完一个命令，还没有来得及记日志就宕机了，那么这个命令和相应的数据就有丢失的风险。如果此时Redis是用作缓存，还可以从后端数据库重新读入数据进行恢复，但是，如果Redis是直接用作数据库的话，此时，命令还没有记入日志，就无法通过日志来进行恢复了。

2）AOF虽然是避免了对当前命令的阻塞，但可能会给下一个操作带来阻塞风险。这是因为，AOF日志也是在主线程中执行的，如果在把日志文件写入磁盘时，磁盘写压力大，就会导致写盘很慢，进而导致后续的操作也无法执行了。

这两个风险都是和AOF写回磁盘的时机有关。这就意味着，如果我们能够控制一个写命令执行完后AOF日志写回磁盘的时机，这两个风险就解除了。



5.三种写回策略

1.对于这个问题，AOF机制给我们提供了三个选择，也就是AOF配置项appendfsync的三个可选值。

1）always，同步写回：每个写命令执行完，立马同步地将日志写回磁盘；

2）EverySec，每秒写回：每个写命令执行完，只是先把日志写到AOF文件的内存缓冲区，每隔一秒把缓冲区中的内容写入磁盘；

3）No，操作系统控制的写回：每个写命令执行完，只是先把日志写到AOF文件的内存缓冲区，由操作系统决定何时将缓冲区内容写回磁盘。

针对避免主线程阻塞和减少数据丢失问题，这三种写回策略都无法做到两全其美。

1）"同步写回"，可以做到基本不丢数据，但是它在每一个写命令后都有一个慢速的落盘操作，不可避免地会影响主线程性能；

2）虽然"操作系统控制的写回"在写完缓冲区后，就可以继续执行后续的命令，但是落盘的时机已经不在Redis手中了，只要AOF记录没有写回磁盘，一旦宕机对应的数据就丢失了。

3）"每秒写回"采用一秒写回一次的频率，避免了"同步写回"的性能开销，虽然较少了对系统性能的影响，但是如果发生宕机，上一秒未落盘的命令操作仍然会丢失。所以，这只能算是，在避免主线程性能和避免数据丢失两者间取了个折中。

![image-20211028095906449](pic\image-20211028095906449.png)

总结一下就是：想要获得高性能，就选择No侧列；如果想要获得高可靠性保证，就选择Always策略；如果允许数据有一点丢失，又希望性能别受太大影响的话，就选择EverySec策略。



6.AOF日志文件太大怎么办？

AOF是以文件的形式在记录接收到的所有写命令。随着接收的写命令越来越多，AOF文件会越来越大。这也意味着，我们要小心AOF文件过大带来的性能问题。

1）文件系统本身对文件大小有限制，无法保存过大的数据；

2）如果文件过大，之后再往里面追加命令记录的话，效率也会变低；

3）如果发生宕机，AOF中记录的命令要一个个被重新执行，用于故障恢复，如果日志文件太大，整个恢复过程就会非常缓慢，这影响到了Redis的正常使用。

这时候，AOF重写机制就登场了。

简单来说，AOF重写机制就是在重写时，Redis根据数据库的现状创建一个新的AOF文件，也就是说，读取数据库中所有的键值对，然后对每一个键值对用一条命令记录它的写入。比如说，当读取了键值对"testkey":"testvalue"之后，重写机制会记录set testkey testvalue这条命令。这样，当需要恢复时，可以重新执行该命令，实现"testkey":"testvalue"的写入。

7.AOF重写会阻塞吗？

和AOF日志由主线程写回不同，重写过程是由后台子进程bgrewriteaof来完成的，这也是为了避免阻塞主线程，导致数据库性能下降。

重写的过程为"一个拷贝，两处日志"

"一个拷贝"就是指，每次执行重写时，主线程fork出后台的bgrewriteaof子进程。此时，fork会把主线程的内存拷贝一份给bg子进程，这里面包含了数据库的最新数据。然后bg子进程就可以在不影响主线程的情况下，逐一把拷贝到数据写成操作，记入重写日志。

"两处日志"又是什么呢？

因为主线程未阻塞，仍然可以处理新来的操作。此时，如果有写操作，第一处日志就是正在使用的AOF日志，Redis会把这个操作写到它的缓冲区。这样一来，即使宕机了，这个AOF日志的操作依然是齐全的，可以用于恢复。第二处日志，就是指新的AOF重写日志。这个操作也会被写入到重写日志的缓冲区。这样，重写日志也不会丢失最新的操作。等到拷贝数据的所有操作记录重写完成后，重写日志记录的这些最新操作也会写入新的AOF文件，以保证数据库最新状态的记录。此时，我们就可以用新的AOF文件替代旧文件了。

![image-20211028102842372](pic\image-20211028102842372.png)

总结来说，每次AOF重写时，Redis会先执行一个内存拷贝，用于重写；然后，使用两个日志保证在重写过程中，新写入的数据不会丢失。而且，因为Redis采用额外的线程进行数据重写，所以这个过程并不会阻塞主线程。在AOF重写过程中，主线程中新写入的数据，也会写入到AOF重写缓冲中。

8.拓展问题

1.AOF日志重写的时候，是由bgrewriteaof子进程来完成的，不用主线程参与，我们今天说的非阻塞也是指子进程的执行不会阻塞主线程。但是，你觉得，这个重写过程有没有其他潜在的阻塞风险呢？如果有，会在哪里阻塞呢?

2.AOF重写也有一个重写日志，为什么它不共享使用AOF本身的日志呢？

答：

1）Redis采用fork子进程重写AOF文件时，潜在的风险包括：fork子进程和AOF重写过程中父进程产生写入的场景。

a、fork子进程，fork这个瞬间一定是会阻塞主线程的(注意，fork并不会一次性拷贝所有内存数据给子进程)，fork采用操作系统提供的写时复制(Copy On Write)机制，就是为了避免一次性拷贝大量内存数据给子进程造成的长时间阻塞问题，但fork子进程需要拷贝进程必要的数据结构，其中一项就是拷贝内存页表(虚拟内存和物理内存的映射索引表)，整个拷贝过程会消耗大量的cpu资源，拷贝完成之前，整个进程都是会阻塞的，阻塞时间取决于整个实例的内存大小，实例越大，内存页表越大，fork阻塞时间越长。拷贝内存页表完成后，子进程和父进程指向相同的内存地址空间，也就是说此时虽然产生了子进程，但是并没有申请与父进程相同的内存大小。那什么时候父子进程才会真正内存分离呢？"写时复制"顾名思义，就是在写发生时，才真正拷贝内存真正的数据，这个过程中，父进程也可能会产生阻塞的风险。

b.fork出的子进程指向父进程相同的内存地址空间，此时子进程就可以执行AOF重写，把内存中的所有数据写入到AOF文件中。但是此时父进程依旧是会有流量写入，如果父进程操作的是一个已经存在的key，那么这个时候父进程就会真正拷贝这个key对应的内存数据，申请新的内存空间，这样逐渐地，父子进程内存数据开始分离，父子进程逐渐拥有各自独立的内存空间。因为内存分配是以页为单位进行分配的，默认4K，如果父进程此时操作的是一个bigkey，重新申请大块内存耗时会变长，可能会产生阻塞风险。另外，如果操作系统开启了内存大页机制(huge page,页面大小为2M),那么父进程申请内存时阻塞的概率将会大大提高，所以在Redis机器上需要关闭Huge page机制。Redis每次fork生成RDB或AOF重写完成后，都可以在Redis log中看到父进程重新申请了多大的内存空间。



2）AOF重写不复用AOF本身的日志，一个原因是父子进程写同一个文件必然会产生竞争问题，控制竞争就意味着会影响父进程的性能。二十如果AOF重写过程失败了，那么原本的AOF文件相当于被污染了，无法做恢复使用。所以Redis AOF重写一个新文件，重写失败，直接删除这个文件就好了，不会对原先的AOF文件产生影响。等重写完成，直接替换旧文件。



## 五、内存快照：宕机后，Redis如何实现快速恢复？

1.Redis避免数据丢失的AOF方法。这个方法的好处，是每次执行只需要记录操作命令，需要持久化的数据量不大。一般而言，只要采用的不是always策略，就不会对性能产生多大影响。但是也因为记录的是操作命令，而不是实际数据，所以用AOF方法进行故障恢复的时候，需要逐一把操作日志都执行一遍。如果操作日志非常多，Redis就会恢复很缓慢，影响到正常使用。这当然你不是理想的结果。



2.另外一种持久化方法：内存快照。所谓内存快照，就是指内存中的数据在某一时刻的状态记录。对于Redis来说，它实现类似照片记录效果的方式，就是把某一时刻的状态以文件的形式写到磁盘上，也就是快照。这样一来，即使宕机，快照文件也不会丢失，数据的可靠性也得到了保证。



3.和AOF相比，RDB记录的是某一时刻的数据，并不是操作，所以，在做数据恢复时，我们可以直接把RDB文件读入内存，很快完成恢复。听起来不错，但内存快照也不是最优选项。



4.我们还需要考虑两个关键问题？

1）对哪些数据做快照？这关系到快照的执行效率；

2）做快照时，数据还能被增删改吗？这关系到Redis是否被阻塞，是否同时正常处理请求。

4.给哪些内存数据做快照？

Redis的数据都在内存中，为了提供所有数据的可靠性保证，它执行的是全量快照，也就是说，把内存中的所有数据都记录到磁盘中。全量数据越大，RDB文件就越大，往磁盘上写数据的时间开销就越大。

Redis提供了两个命令来生成RDB文件，分别是save和bgsave。

1）save：在主线程中执行，会导致阻塞。

2）bgsave：创建一个子进程，专门用于写入RDB文件，避免了主线程的阻塞，这也是Redis RDB文件生成的默认配置。



5.快照数据能修改吗？

bgsave的过程类似于AOF追加写入，也是通过创建子进程，拷贝内存数据并写入磁盘，同时也支持主线程继续写入操作



6.可以每秒做一次快照吗？

如果频繁地执行全量快照，会带来两方面的开销。

一方面，频繁将全量数据写入磁盘，会给磁盘带来很大压力，多个快照竞争有限的磁盘带宽，前一个快照还没有做完，后一个又开始了，容易造成恶性循环。另一方面，bgsave子进程需要通过fork操作从主线程创建出来。虽然，子进程在创建后不会再阻塞主线程，但是fork这个创建过程本身会阻塞主线程，而且主线程的内存越大，阻塞时间越长。如果频繁fork出bgsave子进程，这就会频繁阻塞主线程了。

我们可以做增量快照，所谓增量快照，就是指，做了一次全量快照后，后续的快照对修改的数据进行快照记录，这样可以避免每次全量快照的开销。这么做的前提是，我们需要记住哪些数据被修改了，不要小瞧这个"记住"功能，它需要我们使用额外的元数据信息去记录哪些数据被修改了，这会带来额外的空间开销。

到这里，你可以发现，虽然跟AOF相比，快照恢复速度快，但是快照的频率不好把握，如果频率太低，两次快照间一旦宕机，就可能有比较多的数据丢失。如果频率太高，又产生额外开销，那么还有什么办法既能利用RDB的快速恢复，又能以较小的开销做到尽量少丢数据呢？

Redis4.0中踢出了一个混合使用AOF日志和内存快照的方法。简单来说，内存快照以一定频率执行，在两次快照之间，使用AOF日志记录着期间的所有命令操作。

最后，关于AOF和RDB的选择问题，我想再给你提三点建议：

1）数据不能丢失时，RDB和AOF的混合使用是一个很好的选择

2）如果允许分钟级别的内存丢失，可以只使用RDB；

3）如果只用AOF，有限使用EverySec的配置选项。



## 六、数据同步：主从库如何实现数据一致？

1.Redis具有高可靠性。这里具有两层含义：一是数据尽量少丢失，二是服务尽量少中断。AOF和RDB保证了前者，而对于后者，Redis的做法就是增加副本冗余量，将一份数据同时保存在多个实例上。即使有一个实例出现了故障，需要一段时间才能恢复，其他实例也可以对外提供服务，不影响业务正常使用。

2.Redis提供了主从库模式，以保证数据副本的一致，主从库之间采用的是读写分离的方式。

1）读操作：主库、从库都可以接收

2）写操作：首先到主库执行，然后，主库将写操作同步给从库

3.主从库间如何进行第一次同步

当我们启动多个Redis实例的时候，它们相互之间就可以通过replicaaof(Redis 5.0之前使用slaveof)命令形成主库和从库的关系，之后会按照三个阶段完成数据的第一次同步。

![image-20211028164632114](pic\image-20211028164632114.png)

第一阶段是主从库间建立连接、协商同步的过程，主要是为全量复制做准备。在这一步，从库和主库建立起连接，并告诉主库即将进行同步，主库确认回复后，主从库间就可以开始同步了。具体来说，从库给主库发送psync命令，表示要进行数据同步，主库的runID和复制进度offset两个参数。

1）runID，是每个Redis实例启动时都会自动生成的一个随机ID，用来位移标记这个实例。当从库与主库第一次复制时，因为不知道主库的runID，所以讲runID设置为"?"。

2）offset，此时设为-1，表示第一次复制。

主库收到psync命令后，会用FULLRESYNC响应命令带上两个参数：主库runID和主库目前的复制进度offset，返回给从库。从库收到响应后，会记录下这两个参数。

这里有个地方需要注意，FULLRESYNC响应表示第一次复制采用的是全量复制，也就是说，主库会把当前所有的数据都复制给从库。

在第二个阶段，主库将所有数据同步给从库。从库收到数据后，在本地完成数据加载。这个过程依赖于内存快照生成的RDB文件。

具体来说，主库执行bgsave命令，生成了RDB文件，接着将文件发给从库。从库接收到RDB文件后，会先清空当前数据库，然后加载RDB文件。

在主库将数据同步给从库的过程中，主库不会被阻塞，仍然可以正常接收请求。否则，Redis的服务就被中断了。但是，这些请求中断写操作并没有记录到刚刚生成的RDB文件中。为了保证主从库的数据一致性，主库会在内存中用专门的relication buffer，记录RDB文件生成后收到的所有写操作。

最后，也就是第三个阶段，主库会把第二阶段执行过程中新收到的写命令，再发送给从库。具体的操作时，当主库完成RDB文件发送后，就会把此时replicaion buffer中的修改操作发给从库，从库再重新执行这些操作。这样一来，主从库就实现同步了。

4.主从级联模式分担全量复制时的主库压力

一次全量复制中，对于主库来说，需要完成两个耗时的操作：生成RDB和传输RDB文件。如果从库数量很多，而且都要和主库进行全量复制的话，就会导致主库忙于fork子进程生成RDB文件，进行数据全量同步。fork这个操作会阻塞主线程处理正常请求，从而导致主库响应请求速度变慢。此外，传输RDB文件也会占用主库的网络带宽，同样会给主库的资源使用带来压力。那么，有没有好的解决方法可以分担主库压力呢？

其实是有的，这就是"主-从-从"模式。

在刚才介绍的主从库模式中，所有的从库都是和主库连接，所有的全量复制也都是和主库进行的。现在我们可以通过"主-从-从"模式将主库生成RDB和传输RDB的压力，以级联的方式分散到从库上。

![image-20211028172659939](pic\image-20211028172659939.png)

我们了解了主从库间通过全量复制实现数据同步的过程，以及通过"主-从-从"模式分担主库压力的方式。那么，一旦主库完成了全量复制，它们之间就会一直维护一个网络连接，主库会通过这个连接将后续陆续收到的命令操作再同步给从库，这个过程也称为基于长连接的命令传播，可以避免频繁建立连接的开销。

5.主从库网络断了怎么办？

在Redis2.9之前，如果主从库在命令传播时出现了网络闪断，那么，从库就会和主库重新进行一次全量复制，开销非常大。

从Redis2.8开始，网络断了之后，主从库会采用增量复制的方式继续同步。听名字大概就可以猜到它和全量复制的不同：全量复制是同步所有数据，而增量复制只会把主从库网络断连期间主库收到的命令，同步给从库。

那么，增量复制时，主从库之间具体是怎么保持同步的呢？这里的奥秘就在于repl_backlog_buffer这个缓冲区。我们先来看下它是如何用于增量命令的同步的。

当主从库断连后，主库会把断连期间收到的写操作命令，写入replication_buffer，同时也会把这些操作命令也写入repl_backlog_buffer这个缓冲区。

repl_backlog_buffer是一个环形缓冲区，主库会记录自己写到的位置，从库则会记录自己已经读到的位置。对于主库来说，对应的偏移量就是master_repl_offset，这个值会随着新写入的数据增大；同理从库复制完写操作后，它在缓冲区的读位置也开始偏移。

当主从库的连接恢复之后，从库首先会给主库发送psync命令，并把自己当前的slave_reol_offset发给主库，主库会判断自己的master_repl_offset和slave_repl_offset之间的差距。

在网络断连阶段，主库可能会收到新的写操作命令，所以，一般来说，master_repl_offset会大于slave_repl_offset。此时，主库只用把master_repl_offset和slave_repl_off之间的命令操作同步给从库就行。

![image-20211028193517423](pic\image-20211028193517423.png)

## 七、哨兵机制：主库挂了，如何不间断服务？

1.无论是写服务中断，还是从库无法进行数据同步，都是不能接受的。所以，如果主库挂了，我们就需要运行一个新主库，比如说把一个从库切换成主库，把它当成主库。这就涉及到三个问题：

1）主库真的挂了吗？

2)该选择哪个从库作为主库？

3）怎么把新主库的相关信息通知给从库和客户端呢？

这就要提到哨兵机制了。在Redis主从集群中，哨兵机制是实现主从库自动切换的关键机制，它有效地解决了主从复制模式下故障转移的这三个问题。

2.哨兵机制的基本流程

哨兵其实就是一个运行在特殊模式下的Redis进程，主从库实例运行的同时，它也在运行。哨兵主要负责的就是三个任务：监控、选主和通知。

监控是指哨兵周期性地给所有主从库发送ping命令，检测它们的在线状态；如果规定时间内没有响应，哨兵就会把它们标记为"下线状态"；主库下线则会触发自动切换主库流程。

选主完毕后，会进行通知并进行数据复制。

![image-20211029153321446](pic\image-20211029153321446.png)

在监控和选主过程中，哨兵需要作出两个决策。

1）在监控任务中，哨兵需要判断主库是否处于下线状态；

2）在选主任务中，哨兵也要决定选择哪个从库实例作为主库；



3.主观下线和客观下线

哨兵对主库的下线判断有"主观下线"和"客观下线"。

哨兵进程会使用PINg命令检测它自己和主、从库的网络连接情况，用来判断实例的状态。如果是从库，那么简单标记为"主观下线"，如果是主库，要判断是否是误判，然后开启主从切换，需要减少误判，这样才能减少不必要的开销。

通常会采用多实例组成的集群模式进行部署，这也被称为哨兵集群。引入多个哨兵实例一起来判断，就可以避免单个哨兵因为自身网络状况不好，而误判主库下线情况。同时，多个哨兵的网络同时不稳定的概率比较小，由它们一起做决策，误判率也能降低。

"客观下线"的标准就是，当有N个哨兵实例时，最好要有N/2+1实例判断主库为"主观下线"，才能判定主库为"客观下线"。这样一来，就可以减少误判的概率，也能避免无谓的主从库切换。

4.如何选定新主库？

一般来说，哨兵选择新主库的过程称为"筛选+打分"。简单来说，我们在多个从库中，先按照一定的筛选条件，把不符合条件的从库去掉。然后，我们再按照一定规则，给剩下的从库逐个打分，将得分最高的从库选为新主库。

一般情况下，我们肯定要先保证所选的从库仍然是在线运行。不过，在选主时从库正常在线，这只能表示从库的现状良好，并不代表它就是最适合做主库的。

所以，在选主时，除了要检查从库的当前在线状态，还要判断它之前的网络连接状态。如果从库总是和主库断连，而且断连次数超出了一定的阈值，我们可以相信这个从库的网络并不是太好，就可以把这个从库筛掉了。

具体怎么判断呢？你使用配置项down-after-milliseconds*10。其中down-after-milliseconds是我们认定主从库断连的最大连接超时时间。如果在这个时间内，主从库没有网络连接上，我们就可以认为主从断连了，如果次数超过了十次，就可以认为该从库网络状态不好，不应该选为主库。

接下来就要给剩余的从库打分，我们可以按照三个规则依次进行打分，这三个规则分别是从库优先级、从库复制进度、以及从库ID号。



## 八、哨兵集群：哨兵挂了，主从库还能切换吗？

1.部署哨兵集群，只需要设置主库的IP和端口，并没有配置其他哨兵的连接信息。这些哨兵既然都不知道彼此的地址，又如何组成集群的呢？

2.基于pub/sub机制的哨兵集群。

哨兵实例之间可以互相发现，要归功于Redis的发布订阅机制。从库会订阅主库，然后进行信息交换。在主从集群中。主库有一个名为"__sentinel__:hello"的频道，不同哨兵就是通过它来互相发现，实现互相通信的。

![image-20211101100225616](pic\image-20211101100225616.png)

通过INFO命令，哨兵可以从主库获取所有从库列表。

通过发布订阅机制，哨兵之间可以组成集群，同时，哨兵又通过INFO命令，获得了从库的连接信息。但是哨兵不能只喝主从库连接。因为主从库切换后，客户端也需要知道新主库的连接信息，才能向新主库发送请求操作，所以，哨兵还需要完成把新主库的信息告诉客户端这个任务。

在实际使用哨兵时，我们有时会遇到这样的问题：如何客户端通过监控了解哨兵进行主从切换的过程呢？比如说，主从切换进行到哪一步了？这其实就是要求，客户端能够获取到哨兵集群在监控、选主、切换这个过程中发生的各种事件。

3.基于发布订阅机制的客户端事件通知

从本质上说，哨兵就是一个运行在特定模式下的Redis实例，只不过它并不服务请求操作，只是完成监控、选主和通知任务。所以每个哨兵实例也提供发布订阅机制，客户端可以从哨兵订阅消息。哨兵提供的消息订阅频道有很多，不同频道包含了主从库切换过程中的不同关键事件。

![image-20211101103046210](pic\image-20211101103046210.png)

知道了这些频道之后，你就可以让客户端从哨兵这里订阅消息了。具体的操作步骤是，客户端读取哨兵的配置文件后，可以获得哨兵的地址和端口，和哨兵建立网络连接。然后，我们可以在客户端执行订阅命令，来获取不同的事件消息。

4.由哪个哨兵执行主从切换?

确定由哪个哨兵执行主从切换到过程，和主库"客观下线"的判断过程类似，也是一个"投票仲裁"的过程。在具体了解这个过程前，我们再来看下，判断"客观下线"的仲裁过程。

任何一个实例只要自身判断主库"主观下线"后，就会给其他实例发送is-master-down-by-addr命令。接着，其他实例会根据自己和主库的连接情况，走出Y或N的响应，Y相应于赞成票，N相当于反对票。

![image-20211101104849823](pic\image-20211101104849823.png)

此时，这个哨兵就可以再给其他哨兵发送命令，表明希望由自己来执行主从切换，并让所有其他哨兵进行投票。这个投票的过程称为"Leader选举"。因为最终执行主从切换的哨兵称为Leader，投票的过程就是确定Leader。



## 九、切片集群：数据增多了，是该加内存还是加实例？

1.为了能快速部署并对外提供服务，我们如何选择主机的内存容量呢？

2.Redis保存5000w个键值对，每个键值对的大小是512B，这些键值对所占的内存空间大约是25GB(5000w*512B)。使用一台32GB的Redis,还有7G的内存可以使用，同时开启了RDB做数据做持久化，以确保Redis实例故障后，还能快速恢复。

但是在使用过程中，Redis的响应时间有时候会非常慢。后来使用INFO命令查看Redis的latest_fork_usec指标值(最近一次fork的耗时)，结果显示这个指标值非常高，快到秒级了。其原因在于做RDB持久化时，大量数据需要阻塞主线程，这就导致了Redis响应变慢。

我们这时候可以注意到Redis的切片集群。虽然组件切片集群比较麻烦，但是它可以保存大量数据，而且对Redis主线程的阻塞影响较小。

2.切片集群，也叫分片集群，就是指启动多个Redis实例组成一个集群，然后按照一定的规则，把收到的数据划分成多份，每一份用一个实例来保存。回到我们刚刚的场景中，如果把25GB的数据平均分成5分(当然也可以不做均分)，使用5个实例来保存，每个实例只需要保存5GB。随着用户或数据量的拓展，保存大量数据的情况通常是无法避免的，而切片集群，就是一个非常好的解决方案。

3.如何保存更多数据？

为了保存大量数据，我们使用了大内存云主机和切片集群两种方法。实际上，这两种方法分别对应着Redis应对数据量增多的两种方案:纵向扩展(scale up)和横向扩展(scale out)。

纵向扩展：升级单个Redis实例的资源配置，包括增加内存容量、增加磁盘容量、使用更高配置的CPU。就像下图中，原来的实例内存时8GB，硬盘是50GB，纵向扩展后，内存增加到24GB，磁盘增加到150GB。

横向拓展：横向增加当前Redis实例的个数，原来使用1个8GB内存，50GB磁盘的实例，现在使用三个相同配置的实例。

不过，在只使用单个实例的时候,数据存在哪儿，客户端访问哪儿，都是非常明确的，但是，切片集群不可避免涉及到了多个实例的分布式管理问题。要想把切片集群用起来，我们就需要解决两大问题：

1）数据切片后，在多个实例之间如何分布？

2）客户端怎么确定想要访问的数据在哪个实例上？

4.数据切片和实例的对应分布关系

在切片集群中，数据需要分布在不同实例上，那么，数据和实例之间如何对应呢？这就和接下来我要讲的Redis Cluster方案有关了。不过，我们首先要弄明白切片集群和Redis Cluster的联系和区别。

实际上，切片集群是一种保存大量数据的通用机制，这个机制可以有不同的实现方案。在Redis3.0之前，官方并没有针对切片集群提供具体的方案。从3.0开始，官方提供了一个名为Redis Cluster的方案，用于实现切片集群。Redis Cluster方案中就规定了数据和实例的对应规则。

具体来说，Redis Cluster方案采用hash槽(hash slot)，来处理数据和实例之间的映射关系。在Redis Cluster方案中，一个切片集群共有16384个hash槽，这些hash槽类似于数据分区，每个键值对都会根据它的key，被映射到一个hash槽中。

具体的映射过程分为两大步：首先根据键值对的key，按照CRC16算法计算一个16bit的值；然后，再用这个16bit值对16384取模，得到0~16383范围内的模数，每个模数代表了一个相应编号的hash槽。

那么，这些hash槽又是如何被映射到具体的Redis实例上的呢？

我们再部署Redis Cluster方案时，可以使用cluster create命令创建集群，此时，Redis会自动把这些槽平均分布在集群实例上。例如，如果集群中有N个实例，那么每个实例上的槽个数为16384/N个。

当然我们也可以使用cluster meet命令手动建立实例间的连接，形成集群，在使用cluster addslots命令，指定每个实例上的hash槽个数。使用这个，可以根据实例不同的资源配置进行手动分配。

在集群运行的过程中，key1和key2计算完CRC16值后，对hash槽总个数取模，在根据各自的模数结果，就可以被映射到对应的实例上。

在手动分配hash槽时，需要把16384个槽都分配完，否则Redis集群无法工作。

5.客户端如何定位数据？

一般来说，客户端和集群实例建立连接后，实例就会把hash槽的分配信息发给客户端。但是，在集群刚刚创建的时候，每个实例只知道自己被分配了哪些hash槽，是不知道其他实例拥有的hash槽信息的。

为什么客户端在访问任何一个实例时，都能获得所有的hash槽信息呢？这是因为，Redis实例会把自己的hash槽信息发给和它相连接的其他实例，来完成hash槽分配信息的扩散。当实例之间相互连接后，每个实例就有所有hash槽的映射关系了。

客户端收到hash槽信息后，会把hash槽信息缓存在本地。当客户端请求键值对时，会先计算建所对应的hash槽，然后就可以给相应的实例发送请求了。

1）在集群中，实例有新增或删除，Redis需要重新分配hash槽；

2）为了负载均衡，Redis需要把hash槽在所有实例上重新分布一遍。

此时，实例之间还可以通过相互传递消息，获得最新的hash槽分配信息，但是客户端是无法感知这些变化的。这就导致了，它缓存的分配信息和最新的分配信息不一致。

Redis Cluster提供了一种重定向机制，所谓的重定向，就是指，客户端给一个实例发送数据读写操作时，这个实例上并没有相应的数据，客户端要再给一个新实例发送操作命令。

那么客户端又是怎么知道重定向时的新实例的访问地址呢？当客户端把一个键值对的操作请求发给一个实例时，如果这个实例上并没有这个键值对映射的hash槽，那么这个实例就会给客户端返回Moved命令响应结果，这个结果中包含了新实例的访问地址。

![image-20211101150711996](pic\image-20211101150711996.png)

同时会出现一个问题，重定向的实例可能正在迁移，并未完全迁移完成。这时候会返回一个ASK命令，告知客户端，当前实例正在迁移。下一次再请求slot2的数据，还是会请求到实例2。ASK命令的作用只是让客户端能给新实例发送一次请求，而不像moved那样， 会更改本地缓存，让后续所有命令都发往新实例。



## 十六、异步机制：如何避免单线程模型的阻塞？

1.影响Redis性能的5大方面的潜在因素。Redis内部的阻塞式操作、CPU和NUMA架构的影响、Redis关键系统配置、Redis内存碎片、Redis缓冲区。

2.Redis实例有哪些阻塞点？

1）客户端：网络IO、键值对增删改查操作、数据库读写；

2）磁盘：生成RDB快照，记录AOF日志，AOF日志重写；

3）主从节点：主库生成、传输RDB文件，从库接收RDB文件、清空数据库、加载RDB文件；

4）切片集群：向其他实例传输hash槽信息，数据迁移。

3.和客户端交互时的阻塞点

1）第一个阻塞点：集合全量查询和聚合操作

2）第二个阻塞点：bigkey的删除操作

3）第三个阻塞点：清空数据库

4.与磁盘交互时的阻塞点

1）第四个阻塞点：AOF日志同步写

5.主从节点交互时的阻塞点

1）第五个阻塞点：清空数据库时，再加载RDB文件，造成阻塞。

6.切片集群实例交互时的阻塞点

1）第六种阻塞点：切片集群中bigkey的迁移

7.AOF日志写、删除键值对、清除数据库都可以通过异步线程来处理

![image-20211102101858342](pic\image-20211102101858342.png)

有个地方需要注意一下，异步的键值对删除和数据库清空操作时Redis4.0后提供的功能，Redis也提供了新的命令来执行这两个命令。

1）键值对删除：当你的集合类型中有大量元素(例如有百万级别或者千万级别元素)需要删除时，建议使用UNLINK命令。

2)清空数据库：可以在FLUSHDB和FLUSHALL命令后加ASYNC选项，这样就可以让后台子线程异步地清空数据库。

8.异步删除是Redis4.0以后才有的功能，如果使用的是4.0之前的版本，当你遇到bigkey删除时，我给你个建议：先使用几个类型提供的SCAN命令读取数据，然后再进行删除。因为SCAN每次只读取一部分数据并进行删除，这样可以避免一次性删除大量key给主线程带来的阻塞。

9.对于hash类型的bigkey删除，你可以使用HSCAN命令，每次从HASH集合中获取一部分键值对，再使用HDEL删除这些键值对，这样就可以把删除压力分摊到多次操作中。那么每次删除操作的耗时就不会太长，从而阻塞主线程了。

1）集合全量查询和聚合操作：可以使用SCAN命令，分批读取数据，再在客户端进行聚合计算；

2）从库加载RDB文件：把主库的数据量大小控制在2~4GB左右，以保证RDB文件能以较快的速度加载。



## 二十三、旁路缓存：Redis是如何工作的？

1.Redis用作缓存时，我们会把Redis部署在数据库的前端，业务应用在访问数据时，会先查询Redis中是否保存了相应的数据。此时，会出现两种情况。

1）缓存命中：Redis中有响应数据，就直接读取Redis，性能很快。

2）缓存缺失：Redis中没有保存相应的数据，就从后端数据库中读取数据，性能就会变慢。而且，一旦发生缓存缺失。

2.Redis作为旁路缓存的使用操作

Redis是一个独立的系统软件，和业务应用程序时两个软件，当我们部署了Redis实例后，它只会被动地等待客户端发送请求，然后再进行处理。所以，如果应用程序想要使用Redis缓存，我们就要在程序中增加相应的缓存操作代码。所以我们也称Redis称为旁路缓存。

3.Redis缓存类型

Redis只读缓存和使用直写缓存的读写策略，这两种缓存都会把数据同步到后端数据库中。它们的区别在于：

1.使用只读缓存时，是先把修改写到后端数据库中，再把缓存中的数据删除。当下次访问这个数据时，会以后端数据库中的值为准，重新加载到缓存中。这样做优点是，数据库和缓存可以保证完全一致，并且缓存中永远保留的是经常访问的热点数据。缺点是每次修改操作都会把缓存中的数据删除，之后访问时都会先触发一次缓存缺失，然后从后端数据库加载数据到缓存中，这个过程访问延迟会变大。

2.使用读写缓存时，是同时修改数据库和缓存中的值。这样做的优点是，被修改后的数据永远在缓存中存在，下次访问时，能够直接命中缓存，不用再从后端数据库中查询，这个过程拥有比较好的性能，比较适合先修改又立即访问的业务场景。但缺点是在高并发场景下，如果存在多个操作同时修改同一个值的情况下，可能会导致缓存和数据库的不一致。

3.当使用只读缓存时，如果修改数据库失败了，那么缓存中的数据也不会被删除，此时数据库和缓存中的数据依旧保持一直。而使用读写缓存时，如果是先修改缓存，后修改数据库，如果缓存修改成功，而数据库修改失败了，那么此时数据库和缓存数据就不一致了。如果先修改数据库，再修改缓存也会产生上面所说的并发场景下的不一致。

个人总结，只读缓存时牺牲了一定的性能，有限保证数据库和缓存一致，它更适合于一致性要求较高的业务场景。而如果对于数据库和缓存一致性不高，或者不存在并发修改同一个只读情况，那么使用读写缓存就比较合适，它介意保证更好的访问性能。



## 二十四、缓存满了怎么办？

1.数据访问都是有局部性的。通常所说的"28定理"，80%的请求实际只访问了20%的数据。

2.设置多大的缓存容量合适？

长尾效应：有20%的数据贡献了80%的访问，而剩余的数据虽然体量虽然很大，但只贡献了20%的访问量。这80%的数据在访问量上就形成了一条长长的尾巴，我们也称为"长尾效应"。

重尾效应：20%的数据可能贡献不了80%的访问，而胜于的80%的数据反而贡献了更多的访问量。

这个容量规划不能一概而论，是需要结合应用数据实际访问特征和成本开销来综合考虑。

建议：把缓存容量设置为总数据量的15%~30%，兼顾访问性能和内存空间。

3.Redis有哪些淘汰策略？

Redis4.0之前一共实现了6种内存淘汰策略，在4.0之后，又增加了2种策略。我们可以按照是否会进行数据淘汰把它们分成两类：

1）不进行数据淘汰的策略，只有noeviction这一种。

2）会进行淘汰的7中其他策略。

会进行淘汰的7种策略，我们可以再进一步根据淘汰候选数据集的范围把它们分成两类：

1）在设置了过期时间的数据中进行淘汰，包括volatile-random、volatile-ttl、volatile-lru、volatile-lfu(Redis4.0后新增)四种。

2）在所有数据范围内进行淘汰，包括allkeys-lru、allkeys-random、allkeys-lfu(Redis 4.0后新增)三种。

4.

1）noeviction策略：一旦缓存写满了，再有写请求来时，Redis不再提供服务，而是直接返回错误。

我们再分析下volatile开头的这四种淘汰策略。它们筛选的候选数据范围，被限制在已经设置了过期时间的键值对上，也正因为如此，及时缓存没有写满，这些数据如果过期了，也会被删除。

例如，我们使用Expire命令对一批键值对设置了过期时间后，无论是这些键值对的过期时间快到了，还是Redis的内存使用量达到了maxmemory阈值，Redis都会进一步按照volatile开头的这四种策略的具体筛选规则进行淘汰。

2）volatile-ttl在筛选时，会针对设置了过期时间的键值对，根据过期时间的先后进行删除，越早的越先被删除。

3）volatile-random就像它的名称一样，在设置了过期时间的键值对中，进行随机删除。

4）volatile-lru会使用lru算法筛选设置了过期时间的键值对。

5）volatile-lfu会使用lfu算法选择设置了过期时间的键值对。

LFU算法是在LRU算法的基础上，同时考虑了数据的访问时效性和数据的访问次数，可以看做是对淘汰策略的优化。

相对于volatile-ttl、volatile-random、volatile-lru、volatile-lfu这四种策略淘汰的是设置了过期时间的数据，allkeys-lru、allkeys-random、allkeys-lfu这三种淘汰策略的备选淘汰数据范围，就扩大到了所有键值对，无论这些键值对是否设置了过期时间。它们筛选数据进行淘汰的规则是：

6）allkeys-random策略，从所有键值对中随机选择并删除数据；

7）allkeys-lru策略，使用LRU算法在所有数据中筛选；

8）allkeys-lfu，使用lfu算法在所有数据中筛选；

这样就是说，如果一个键值对被删除策略选中了，即使它的过期时间还没到，也需要被删除，当然如果它的过期时间到了，但未被策略选中，同样也会被删除。

5.三个建议。

1）优先使用allkeys-lru策略。如果你的业务数据中有明显的冷热数据区分，建议使用allkeys-lru策略；

2）如果业务应用的数据访问频率相差不大，没有明显的冷热数据区分，建议使用allkeys-random策略，随机选择淘汰的数据就行。

3）如果你的业务中有置顶的需求，比如置顶新闻、置顶适配，那么可以使用volatile-lru策略，同时不给这些指定数据设置过期时间。这样一来，这些需要置顶的数据一直不会删除，而其他数据会在过期时根据LRU规则进行筛选。

6.Redis在用作缓存时，使用只读缓存或读写缓存的哪种模式？

1.只读模式：每次修改直接写入后端数据库，如果Redis不命中，则什么都不用操作；如果命中，则先删缓存，再写数据库，等到下次从数据库中加载到缓存中。

2.读写缓存模式+同步直写策略：由于Redis在淘汰数据时，直接在内部删除键值对，外部无法介入处理脏数据写回数据库，所以使用Redis做读写缓存时，只能采用同步直写策略，修改缓存的同时也要写入到后端数据库，从而保证修改操作不丢失但这种方案在并发场景下会导致数据库和缓存的不一致，需要在特定业务场景下或者配合分布式锁使用。

当一个系统引入缓存时，需要面临的最大问题就是，如何保证缓存和后端数据库的一致性问题，最常见的3个解决方案分别是Cache Asice、Read/Write Throught和Write Back缓存更新策略。

1.Cache Aside策略：就是只读缓存模式。读模式命中缓存直接返回，否则从后端加载到缓存再返回。写操作就是直接更新数据库，然后删除缓存。这种策略的优点是一切以后端数据库为准，可以保证缓存和数据库的一致性。缺点是写操作会让缓存失效，再次读取时需要从数据库中加载。这种策略是我们在开发软件时最常用的，在使用MemeCached或Redis时一般都采用这种方案。

2.Read/Write Thought策略：应用层读写只需要操作缓存，不需要关心后端数据库。应用层在操作缓存时，缓存层会自动从数据库中加载或写回到数据库中。这种策略的优点是，对于应用层的使用非常友好，只需要操作缓存即可，缺点是需要缓存层支持和后端数据库的联动。

3.Write Back策略：类似于文章所讲的读写缓存模式+异步写回策略。写操作只写缓存，比较简单。而读操作如果命中缓存则直接返回，否则需要从数据库中加载到缓存中，在加载之前，如果缓存已满，则先把需要淘汰的缓存数据写回到后端数据库中，再把对应的数据放入到缓存中。这种策略的优点是，写操作飞快(只写缓存)，缺点是如果数据还未来得及写入后端数据，系统发生异常会导致缓存和数据库的不一致。这种策略经常使用在操作系统页缓存中，或者应对大量写操作的数据库引擎中。

除了以上提到的缓存和数据库的更新策略之外，还有一个问题就是操作缓存或数据库发生异常时如何处理？例如缓存操作成功，数据库操作失败，或者反过来，还是有可能会产生不一致的情况。

比较简单的解决方案是，根据业务设计好更新缓存和数据库的先后顺序来降低影响，或者给缓存设置较短的有效期来降低不一致的时间。如果需要严格保证缓存与数据库的一致性，即保证两者操作的原子性，这就涉及到分布式事务问题了。



## 二十五、缓存异常（上）：如何解决缓存和数据库的数据不一致问题？

1.在实际应用Redis缓存时，我们经常会遇到一些异常问题：缓存中的数据与数据库中的不一致；缓存雪崩；缓存击穿和缓存穿透。

2.缓存和数据库中的数据不一致是如何发生的?

"数据的一致性"包含了两种情况：

1）缓存中有数据，那么，缓存的数据值需要和数据库中的值相同；

2）缓存中本身没有数据，那么，数据库中的值必须是最新值。

3.对于读写缓存来说，如果要对数据进行增删改，就需要在缓存中进行，同时还要根据采取的写回策略，决定是否同步写回到数据库中。

1）同步直写策略：写缓存时，也同步写数据库，缓存与数据库中的数据一致。

2）异步写回策略：写缓存时不同步写数据库，等待数据从缓存中淘汰时，再写回到数据库。使用这种策略时，如果数据还没有写回数据库，缓存就发生了故障。那么此时，数据库就没有最新的数据了。

在有些场景下，我们对数据的一致性要求不是那么高，比如说缓存的是电商商品的非关键属性或者短视频的创建或修改时间等，那么我们就可以使用异步写回策略。



4.对于只读缓存来说，如果有新增数据，会直接写入数据库；而有数据删改时，就需要把只读缓存中的数据标记为无效。这样一来，应用后续再访问这些增删改数据时，因为缓存中没有相应数据，就会发生缓存缺失。此时，应用再从数据库中把数据读入缓存，这样后续再访问数据时，就能够直接从缓存中读取。

1）新增数据

如果是熙增数据，数据会直接写到数据库中们不用对缓存做任何操作。此时，缓存中本身是没有新增数据，而数据库中是最新值，这种情况符合我们刚刚所说的一致性的第二种情况，所以说数据库和缓存中的数据是一致的。

2）删改数据

如果发生删改操作，应用既要更新数据库，也要在缓存中删除数据。这两个操作如果无法保证原子性，也就是说，要不都完成，要不都没完成，此时，就会出现数据不一致问题。

![image-20211102212429194](pic\image-20211102212429194.png)

应用要把数据X的值从10更新为3，先在Redis缓存中删除了X的缓存值，但是更新数据库却失败了。。如果此时有其他并发的请求访问X，会发现Redis中缓存缺失，紧接着，请求就会访问数据库，读到的却是旧值10。

![image-20211102212834233](pic\image-20211102212834233.png)

如果我们先更新数据库，但是，在删除缓存时失败了 ，那么数据库中的值是新值，而缓存中的是旧值，这肯定是不一致的。这个时候，如果有其他并发请求来访问数据，按照正常的缓存访问流程，就会现在缓存中查询，但此时，就会读到旧值。

![image-20211102212851183](pic\image-20211102212851183.png)

到这里我们可以看到，在更新数据库和删除缓存值的过程中，无论这两个操作的执行顺序谁先谁后，只要有一个操作失败了，就会导致客户端读取到旧值。

5.如何解决数据不一致问题？

首先一种方法：重试机制。

具体来说，可以把要删除的缓存值或者要更新的数据库暂存到消息队列中(例如用kafka)。当应用没有能够成功地删除缓存值或者是更新数据库值时，可以从消息队列中重新读取这些值，然后再次进行更新或删除。

如果能够成功地删除或更新，我们就要把这些值从消息队列中去除，以免重复操作，此时，我们也可以保证数据库和缓存的数据一致性了。否则的话，我们还需要再次进行重试。如果重试超过一定次数，还是没有成功，我们就需要向业务层发送报错信息了。

下图显示了先更新数据库，再删除缓存值时，如果缓存删除失败，再次重试后删除成功的情况。

![image-20211102214225474](pic\image-20211102214225474.png)

刚刚说的是在更新数据库和删除缓存值的过程中，其中一个操作失败的情况，实际上，即使这两个操作第一次执行时都没有失败，当有大量并发请求时，应用还是有可能读到不一致的数据。

同样，我们按照不同的删除和更新顺序，分为两种情况来看。在这两种情况下，我们的解决方法也有所不同。

情况一：先删除缓存，再更新数据库。

假设线程A删除缓存后，还没来得及更新数据库(网络延迟)，线程B就开始读取数据了，那么这个时候，线程B会发现缓存缺失，就只能去数据库读取。这回带来两个问题。

1）线程B读到了旧值

2）线程B在缓存缺失的情况下读取的数据库，所以它还会把旧值写入缓存，这可能会导致其他线程从缓存中读到旧值

![image-20211102214813492](pic\image-20211102214813492.png)

解决方案：在线程A更新完数据库值之后，我们可以让它先sleep一小段时间，再进行一次缓存删除操作。（延迟双删）



情况二：先更新数据库值，再删除缓存值。

如果线程A更新了数据库中的值，但还没来得及删除缓存值，线程B就开始读取数据了，那么此时，线程B查询缓存时，发现缓存命中，就会读取旧值。不过在这种情况下，如果并发线程不多的话，就不会有很多请求读取到旧值。而且很快线程A也会很快删除。这种情况对业务的影响较小。



到这里，我们了解到了，缓存和数据库的数据不一致一般是由两个原因导致的。。

1）删除缓存值或更新数据库失败，而导致数据不一致，你可以使用重试机制确保删除或更新操作成功

2）在删除缓存值，更新数据库的这两步操作中，如果有其他线程并发读操作，可能导致其他线程读取到旧值，应对方案是延迟双删。

6.数据在删改操作时，如果不是删除缓存值，而是直接更新缓存的值，你觉得和删除缓存值相比有啥好处和不足？

这种情况相当于把Redis当做读写缓存使用，删改操作同时操作数据库和缓存。

1.先更新数据库，再更新缓存：如果更新数据库成功，但缓存更新失败，此时数据库中是最新值，但缓存中是旧值，后续的读请求会直接命中缓存，得到的是旧值。

2.先更新缓存，再更新数据库：如果更新缓存成功，但数据库更新失败，此时缓存中是最新值，数据库中是旧值，后续读请求会直接命中缓存，但得到的是最新值，断球对业务影响不大。但是一旦缓存被淘汰之后，读请求就会从数据库中重新加载旧值到缓存中，之后的读请求会从缓存中读取旧值，对业务产生影响。

同样地，针对这种其中一个操作可能失败的情况，也可以使用重试机制解决，把第二步操作放入到消息队列中，消费者从消息队列取出消息，再更新缓存或数据库，成功后把消息从消息队列删除，否则进行重试，以此达到数据库和缓存的最终一致。

以上是没有并发请求的情况。如果存在并发读写，也会产生不一致，分为以下4种场景。

1.先更新数据库，再更新缓存，写+读并发：线程A先更新数据库，之后线程B读取数据，此时线程B会命中缓存，读取到旧值，之后线程A更新缓存成功，后续的请求会命中缓存得到最新值。这种场景下，线程A未更新完缓存之前，在这期间的读请求会短暂读到旧值，对业务暂时影响。

2.先更新缓存，再更新数据库，写+读并发：线程A先更新缓存成功，之后线程B读取数据，此时线程B命中缓存，读取到最新值后返回，之后线程A更新数据库成功。这种场景下，虽然线程A还未更新完数据库，数据库会与缓存存在短暂不一致，但之后的读请求都能直接命中缓存，获取到最新值，所以对业务没影响。

3.先更新数据库，再更新缓存，写+写并发：线程A和线程B同时更新同一条数据，更新数据库的顺序是先A后B，但是更新数据的顺序是先B后A，这也会导致数据库和缓存的不一致。

4.先更新缓存，再更新数据库，写+写并发：和场景3类似，线程A和线程B同时更新同一条数据，更新缓存的顺序是先A后B，但更新数据库顺序不一致。

针对场景1和2对业务影响较小，场景3和4会造成数据库和缓存的不一致影响较大。也就是说，在读写缓存模式下，写+读并发对业务影响较小，而写+写并发时，会造成数据库和缓存的不一致。

针对场景3和4的解决方案是，对于写请求，需要配合分布式锁使用。写请求进来，针对同一个资源的修改操作，先加分布式锁，这样同一时间只允许一个线程去更新数据库和缓存，没有拿到锁的线程把操作放入到队列中，延时处理。用这种方式保证多个线程操作同一资源的顺序性，一次保证一致性。

综上，使用读写缓存同时操作数据库和缓存时，因为其中一个操作失败导致不一致的问题，同样可以通过消息队列重试来解决。而在并发的场景下，读+写对业务没有影响或者影响较小，而写+写并发时需要配合分布式锁的使用，才能保证缓存和数据库的一致性。

另外，读写缓存模式由于会同时更新和缓存，优点是，缓存中会一直有数据，如果更新操作后悔立即再次访问，可以直接命中缓存，能够降低读请求对于数据库的压力(没有了只读缓存的删除缓存导致缓存缺失和再加载的过程)。缺点是，如果更新后的数据，之后很少被访问到，会导致缓存中保留的不是最热的数据，缓存利用率不高(只读缓存中保留的都是热点数据)，所以读写缓存比较适合用于读写相当的业务场景。



## 二十六、缓存异常（下）：如何解决缓存雪崩、击穿、穿透难题？

1.缓存雪崩是指应用请求无法在Redis缓存中处理，紧接着，应用将大量请求发送到数据库层，导致数据库层的压力激增。

缓存雪崩一般是由两个原因导致的，应对方案也不一样，我们一个个来看。

1）第一个原因是：缓存中有大量数据同时过期，导致大量请求无法得到处理。

具体来说，当数据保存在缓存中，并且设置了过期时间时，如果在某一时刻，大量数据同时过期，此时，应用再范根这些数据的话，就会发生缓存缺失。紧接着，应用就会把请求发送给数据库。如果应用的并发请求量很大，那么数据库的压力也会很大，这就会进一步影响到数据库的其他业务的正常使用。

针对大量数据同时失效带来的缓存雪崩问题，我给你提供两种解决方案。

1）我们可以避免给大量的数据设置相同的过期时间。如果业务层的确要求有些数据同时失效，你可以在用EXPIRE命令给每个数据设置过期数据时，给这些数据的过期时间增加一个较小的随机数(例如，随机增加1-3分钟)，这样一来，不同数据的过期时间有所差别，但差别不会很大，既避免了大量数据同时过期，同时也保证了这些数据基本在相近时间内失效，仍然能满足业务需求。

2）除了微调过期时间，我们还可以通过服务降级，来应对缓存雪崩。所谓的服务降级，是指发生缓存雪崩时，针对不同的数据采取不同的处理方式。

1）当业务应用访问的是非核心数据(例如电商商品属性)，暂时停止从缓存中查询这些数据，而是直接返回预定义、空值或是错误信息；

2）当业务应用访问的是核心数据(例如电商商品库存)时，仍然允许查询缓存，如果缓存缺失，也可以继续通过数据库读取。

这样一来，只有部分过期数据的请求会发送到数据库，数据库的压力就没有那么大了。

除了大量数据同时失效会导致缓存雪崩，还有一种情况也会发生缓存雪崩，那就是，Redis缓存实例发生了故障宕机，无法处理请求，这就会导致大量请求一下子挤压到数据库层，从而发生缓存雪崩。

2.因为Redis实例宕机导致的缓存雪崩，有两点建议：

1）第一个建议，是在业务系统中实现服务熔断或请求限流机制。

所谓的服务熔断，是指在发生缓存雪崩时，为了防止引发连锁的数据库雪崩，甚至是整个系统的崩溃，我们暂停业务应用对缓存系统的接口访问，等到Redis缓存实例恢复后，再允许请求发送到缓存系统。

这样一拉，我们就避免了大量请求因为缓存缺失，而积压到数据库系统，保证了数据库系统的正常运行。在业务系统运行时，我们可以对Redis缓存进行监控。如果我们发现Redis服务宕机了，这时候我们就可以开启服务熔断机制。

服务熔断机制虽然可以保证数据库的正常运行，但是也暂停了整个缓存系统的访问，对业务影响范围大。为了尽可能减少这种影响，我们也可以进行请求限流。这里说的请求限流，是指，我们在业务系统的请求入口前端控制每秒进入系统的请求数，避免过多的请求被发送到数据库。

使用熔断和限流机制，来应对Redis实例宕机导致的缓存雪崩问题，属于事后解决方案。

2）第二个建议是事前预防

可以通过主从节点的方式构建Redis缓存高可靠集群。如果Redis缓存的主节点故障宕机了，从节点还可以切换成主节点，继续提供缓存服务。避免了由于缓存实例宕机而导致的缓存雪崩问题。

3.缓存击穿是指针对某个非常频繁的热点数据的请求，无法在缓存中进行处理，紧接着，访问该数据的大量请求，一下子都发送到了后端数据库，导致数据库压力激增，会影响数据库处理其他请求。缓存击穿的情况通常发生在热点数据过期失效之后。

我们的解决方案也比较直接，对于访问特别频繁的热点数据，我们就不设置过期时间了。这样一来，对热点数据的访问请求，都可以在缓存中处理。

4.缓存穿透：当数据既不在缓存中，也不在数据库中，导致请求在访问缓存时，发生缓存缺失，再去访问数据库时，发现数据库也不存在该数据。此时应用无法从数据库中读取数据再写入缓存，这时候缓存就变成了摆设。

缓存穿透发生在什么时候？一般有两种情况。

1）业务层误操作：缓存中的数据和数据库中的数据被误删除了，所以缓存和数据库中都没有数据。

2）恶意攻击：专门访问数据库中没有的数据。

5.缓存穿透的三种解决方案。

1）缓存空值或缺省值。

一旦发生缓存穿透，我们可以针对查询的数据，在Redis中缓存一个空值或是和业务层协商的缺省值(例如，库存的缺省值可以设为0)。

2）第二种方案是，使用布隆过滤器快速判断数据是否存在，避免从数据库中查询数据是否存在，减轻数据库压力。

3）最后一种方案是，在请求入口的前端进行请求检测。缓存穿透的一个原因是有大量的恶意请求访问不存在的数据，所以，一个有效的应对方案是在请求入口前端，对业务系统接收到的请求进行合法性检测，把恶意的请求拦截过滤掉，不让它们访问后端缓存和数据库。

6.服务熔断、服务降级、请求限流，这些方法都属于"有损方案"，在保证数据库和缓存的稳定运行，会对业务系统有所影响。

所以建议使用预防措施：

1）针对缓存雪崩，合理设置过期时间，搭建高可用缓存集群

2）针对缓存击穿，对于热点数据不需要设置过期时间

3）针对缓存穿透，提前在应用入口过滤掉非法请求，以及避免缓存数据库误删操作。



## 二十七、缓存被污染了，该怎么办？

1.什么是缓存污染呢？在一些场景下，有些数据被访问的次数非常少，甚至只会被访问一次。当这些数据服务完成访问请求后，如果还继续留存在缓存中的话，就只会白白占用缓存空间。这种情况，就是缓存污染。

当缓存污染不严重时，只有少量数据占据缓存空间，此时，对缓存系统的影响不大。但是一旦缓存污染变得严重后，就会有大量不再访问的数据滞留在缓存中。如果这时数据占满了缓存空间，我们再往缓存中写入新数据时，就需要先把这些数据逐步淘汰出缓存，这就引入了额外的操作时间开销，进而影响应用的性能。

2.如何解决缓存污染问题？

要解决缓存污染，那就是要把不会再被访问的数据筛选出来并淘汰掉。这样就不用等到缓存被写满以后，再逐一淘汰掉旧数据之后，才能写入新数据了。而哪些数据能留存在缓存中，是由缓存的淘汰策略决定的。

1）volatile-random和allkeys-random这两种策略。它们都是通过随机挑选数据的方式，来筛选即将被淘汰的数据。这个挑选与数据的访问情况无关。所以这两种策略，在避免缓存污染这个问题上的效果非常有限。

2）volatile-ttl策略不再是随机淘汰，针对的是设置了过期时间的数据，把这些数据中剩余存活时间最短的筛选出来并淘汰掉。但是这种筛选方式与数据再次访问情况无关，也会出现可能的数据淘汰之后，被再次访问导致的缓存缺失问题。

3）volatile-lru，会在候选数据集中淘汰掉lru字段值最小的数据(也就是访问时间最久的数据)。因为只看数据的访问时间，使用LRU策略在处理扫描式单次查询操作时，无法解决缓存污染。所谓的扫描式单次查询操作，就是指应用对大量的数据进行一次全体读取，每个数据都会被读取，而且只会被读取一次。此时，因为这些被查询的数据刚刚被访问过，所以lru字段都很大。

4）Redis4.0版本开始增加了LFU淘汰策略上，为每个数据增加了一个计数器，来统计这个数据的访问次数。当使用LFU策略筛选淘汰数据时，首先会根据数据的访问次数来进行筛选，把访问次数最低的数据淘汰出缓存。如果两个数据的访问次数相同，LFU策略再比较这两个数据的访问时效性，把距离上一次访问时间更久的数据淘汰出缓存。

LFU策略又是如何实现的呢？既然LFU策略是LRU策略上做的优化，那它们的实现必定有些关系。

为了避免操作链表的开销，Redis在实现LRU策略时使用了两个近似的方法。

1）Redis使用RedisObject结构来保存数据，RedisObject结构中设置了一个lru字段，用来记录数据的访问时间戳

2）Redis并没有为所有的数据维护一个全局的链表，而是通过随机采样的方式，选取一定数据的数据放入候选集合，后续在候选集合中进行筛选。



## 二十八、如何基于SSD实现大容量Redis？

1.我们再应用Redis时，随着业务数据的增加(比如说电商业务中，随着用户规模和商品数量的增加)，就需要Redis能保存更多的数据。你可能会想到使用Redis切片集群，把数据分散保存到多个实例上。但是如何要保存的数据总量很大，但是每个实例保存的数据量很小，就会导致集群的实例规模增加，这会让集群的运维管理变得复杂，增加开销。

同时可以通过增加Redis单实例的内存容量，形成大内存实例，每个实例可以保存更多的数据，这样一来，在保存相同的数据总量时，所需要的大内存实例的个数就会减少，就可以节省开销。

但是同样这也会导致新的问题：基于大内存的大容量实例在恢复、主从同步过程中，会引发一系列的潜在问题，比如恢复时间长、主从切换开销大、缓冲容易溢出。

推荐使用固态硬盘(SSD)。它的成本很低(每GB的成本约是内存的十分之一)，而且容量大，读写速度快，我们可以基于SSD来实现大容量的Redis实例。360公司和基础架构组联合开发的Pika键值数据库，正好实现了这个需求。

设计目标：

1）单实例可以保存大容量数据，同时要避免实例恢复和主从同步时的潜在问题

2）和Redis的数据类型保持兼容，可以支持使用Redis的应用平滑地迁移到Pika上。所以，如果你一直在使用Redis，并且想使用SSD来扩展单实例容量，Pika就是一个很好的选择。

2.大内存Redis实例的潜在问题

Redis使用内存保存数据，内存容量增加后，就会带来两方面的潜在问题，分别是，内存快照RDB生成和恢复效率低，以及主从节点全量同步时长增加、缓冲区易溢出。

Pika是如何解决该问题的呢？

Pika键值数据库的整体架构包括了五个部分，分别是网络框架、Pika线程模块、Nemo存储模块、RocksDB和binlog机制。

3.Pika的优势和不足。

优势：

1）Pika可以基于SSD保存大容量数据

2）Pika与Redis进行兼容

3）重启实例快，Pika不用从RDB或者AOF数据文件中读取进行回放操作，可以直接读取SSD中的数据

4）主从库执行全量同步的风险低。Pika通过binlog机制实现写命令的增量同步，不再受内存缓冲区大小的限制，所以，即使在数据库量很大导致主从库同步耗时很长的情况下，Pika也不用担心缓冲区溢出而触发的主从库重新全量同步。

不足：

1）因为是从SSD上进行操作，会降低数据的访问性能，性能下降约41%。



## 二十九、无锁的原子操作：Redis如何应对并发访问？

1.为了实现并发控制要求的临界区代码互斥执行，Redis的原子操作采用了两种方法：

1）把多个操作在Redis中实现一个操作，也就是单命令操作；

2）把多个操作写到一个lua脚本，以原子性方式执行单个lua脚本。

Redis会把整个Lua脚本作为一个整体执行，在执行过程中不会被其他命令打断，从而保证Lua脚本中操作的原子性。如果我们有多个操作要执行，但是又无法用INCR、DECR这种命令操作来实现，就可以把这些要执行的操作编写到一个Lua脚本中。然后我们可以使用Redis的Eval命令来执行脚本。这样一来，这些操作在执行时就具有了互斥性。

eg：当一个业务应用的访问用户增加时，我们有时需要限制某个客户端在一定时间范围内的访问次数，比如爆款商品的购买限流、社交网络中的每分钟点赞次数限制等。那该怎么限制呢？我们把客户端IP作为Key，把客户端的访问次数作为value，保存到Redis中。客户端每访问一次后，我们就用INCR增加访问次数。但是，客户端限流的逻辑不只有计数，还包括访问次数判断和过期时间设置。

对于这些操作，我们同样需要保证它们的原子性。否则，如果客户端使用多线程访问，访问次数初始值为0，第一个线程执行了INCR(ip)操作后，第二个线程紧接着也执行了INCR(ip)，ip对应的访问次数就被增加到了2，我们就无法再对这个ip设置过期时间了。这样就会导致，这个ip对应的客户端访问次数到了20次，即使过了60s，也不能再访问，显然不符合业务要求。

所以这个例子无法用Redis单个命令来实现，此时，我们就可以使用lua脚本来保证并发控制。我们可以把访问次数加1、判断访问次数是否为1，以及设置过期时间这三个操作写入一个lua脚本。



## 三十、如何使用Redis实现分布式锁？

1.使用setnx和del命令组合实现分布式锁，存在两个潜在风险。

1）假如某个客户端执行了setnx命令、加锁后，紧接着却在操作共享数据中出现了异常，如果一直没有执行最后的del命令释放锁，这会影响业务应用。这个可以通过给锁变量设置一个过期时间。

2）假如客户端A执行了setnx命令加锁后，假设客户端b执行了del命令释放了锁，线程c又获取了锁，这也是业务所不能容忍的。

3）如果我们是通过单实例来实现的分布式锁，假如这个Redis实例发生故障宕机了，锁变量就不可用了，客户端也无法进行锁操作了，这就影响到了业务的正常执行。所以我们在实现分布式锁时，还需要保证锁的可靠性。

2.基于多个Redis节点实现高可靠的分布式锁

为了避免Redis实例故障而导致的锁无法正常工作的问题，Redis的开发这Antirez提出了分布式锁算法RedLock。

RedLock算法的基本思路，是让客户端和多个独立的Redis实例一次请求加锁，如果客户端能够和半数以上的实例成功地完成加锁操作，那么我们就认为，客户端成功地获得分布式锁了，否则加锁失败。这样一来，即使有单个Redis实例发生故障，因为锁变量在其他实例上也有保存，所以客户端可以正常地进行锁操作，锁变量并不会丢失。

3.RedLock算法的执行步骤。RedLock算法的实现需要有N个独立的Redis实例。接下来，我们可以分成3步来完成加锁操作。

1）客户端获取当前时间

2）客户端按照顺序依次向N个Redis实例执行加锁操作

3）一旦客户端完成了和所有Redis实例的加锁操作，客户端就要计算整个加锁过程的总耗时。

客户端只有在满足下面的这两个条件时，才能认为是加锁成功。

1）客户端从超过半数（大于N/2+1）的Redis实例上成功获取到了锁

2）客户端获取锁的总耗时没有超过这把锁的有效时间。



三十一、事务机制：Redis能实现ACID属性吗？

1.事务是数据库的一个重要功能。所谓的事务，就是指对数据进行数据读写的一系列操作。事务在执行时，会提供专门的属性保证，包括原子性(Atomicity)、一致性(consistency)、隔离性(isolation)和持久性(Durability)，也就是ACID属性。这些属性既包括了对事务执行结果的要求，也有对数据库在事务执行前后前后端数据状态变化的要求。

2.Redis如何实现事务？

事务的执行过程包括三个步骤，Redis提供了MULTI、EXEC两个命令来完成这三个步骤。

1）客户端要使用一个命令显式地表示一个事务的开启。在Redis中这个命令就是MULTI。

2）客户端把事务中本身要执行的具体操作(例如CRUD数据)发送给服务端。这些操作就是Redis本身提供的数据读写命令，例如GET、SET等。不过这些命令虽然被客户端发送到了服务端，但Redis实例只是把这些命令暂存到一个命令队列中，并不会立即执行。

3）客户端向服务端发送比较事务的命令，让数据库实际执行第二部中发送的具体操作。Redis提供的EXEC命令就是执行事务提交的。当服务器收到EXEC命令后，才会实际执行命令队列中的所有命令。

3.Redis对于错误的语法命令，会在执行前做一次检查，然后放弃整个事务中的命令执行流程。如果没有语法错误，对于那些已经执行的命令，不会再进行回滚。虽然Redis中提供了了DISCARD命令，但是这个命令只能用来放弃事务执行，把暂存的命令队列清空。

4.一致性

1）命令入队时报错，这时候数据库的数据是一致的，入队的命令还没来得及执行。

2）命令入队时没报错，执行时报错。这时候数据库是一致的

3）EXEC命令执行时，实例发生故障。这时候实例会重启，一致性和恢复之后有关。根据实例是否开启了AOF和RDB来讨论。

1）如果我们没有开启RDB或AOF，数据都没有了，数据库是一致的。

2）如果我们使用了RDB快照，RDB快照不会在事务执行时执行。所以使用RDB恢复时，数据库也是一致的。

3）当我们使用AOF日志，日志中记录了部分操作，使用redis-check-aof清除事务中已经完成的操作，数据库恢复后也是一致的。

5.隔离性

事务的隔离性保证，会受到和事务一起执行的并发操作的影响。而事务执行又可以分为命令入队(EXEC命令执行前)和命令实际执行后(EXEC命令执行后)两个阶段，所以，我们就针对这两个阶段，分成两种情况来分析：

1）并发操作在EXEC命令前执行，此时，隔离性的保证要使用WATCH机制来实现，否则隔离性无法保证；

2）并发操作在EXEC后执行，此时隔离性可以保证。

WATCH机制的作用是，在事务执行前，监控一个或多个键的值变化情况，当事务调用EXEC命令执行时，WATCH机制先检查监控的键是否被其他客户端修改了。如果修改了，就放弃事务执行，避免事务的隔离性被破坏。然后，客户端可以再次执行，此时，如果没有并发修改事务数据的操作了，事务就能正常执行了，隔离性也得到了保证。

6.持久性

因为Redis是内存数据库，所以数据是否持久化保存完全取决于Redis的持久化配置模式。

如果Redis没有使用RDB或AOF，那么事务的持久化属性肯定得不到保证。如果Redis使用了RDB模式，那么，在一个事务执行后，而下一次的RDB快照还未执行前，如果发生了实例宕机，这种情况下，事务修改的数据也是不能保证持久化的。

如果Redis开启了AOF模式，因为AOFF模式的三种配置选项no、everysec和always都会存在数据丢失的情况，所以事务的持久性属性也还是得不到保证。所以，不管Redis采用什么持久化模式，事务的持久性属性是得不到保证的。

7.建议使用事务的时候配合pipeline使用，一次性将所有命令打包好全部方法送给服务端，这样减少了网络IO次数。



## 三十二、Redis主从同步与故障切换，有哪些坑？

1.主从数据不一致

主从数据不一致，指的是客户端从从库中和主库中读取的数据并不一致。

出现这个问题的原因，是主从库之间的命令复制是异步进行的。

1）主从库间的网络可能会有传输延迟

解决方案：在硬件环境配置方面，我们要尽量保证主从库间的网络连接状况良好。

2）从库正在处理其他复杂度高的命令(例如集合操作)而阻塞。此时，从库需要处理完当前的命令，才能执行主库发送的命令操作，这就会造成主从数据不一致。

解决方案：我们还可以开发一个外部程序来监控主从库间的复制进度。因为Redis的INFO replication命令可以查看主库接收写命令的进度信息(master_repl_offset)和从库复制写命令的进度信息(slave_repl_offset)，所以我们可以一个开发监控程序，先用INFO replication命令查到主、从库的进度，然后，我们用master_repl_offset减去slave_repl_offset，这样就能得到从库和主库间的复制进度差值。

2.除了主从数据不一致以外，我们有时还会在从库中读取到过期的数据。

其实，这是由Redis的过期数据删除策略引起的。Redis同时使用了两种策略来删除过期的数据，分别是惰性删除策略和定期删除策略。

如果客户端从主库上读取留存的过期数据，主库会触发删除操作，此时，客户端并不会读到过期数据。但是，从库本身不会执行删除操作，如果客户端在从库中访问留存的过期数据，从库并不会触发数据删除。那么，从库会给客户端返回过期数据吗？

这个和你使用的Redis版本有关。如果你使用的是Redis3.2之前的版本，那么。从库在服务读请求时，并不会判断数据是否过期，而是会返回过期数据。在3.2版本后，Redis做了改进，如果读取的数据过期了，从库虽然不会删除，但是会返回空值，这就避免了客户端读到过期数据。所以，在应用主从集群时，尽量使用Redis3.2及以上版本。

如果使用了3.2版本以上的Redis，其实还是有可能会读到过期数据。

这跟Redis用于设置过期时间的命令有关，有些命令给数据设置的过期时间在从库上可能被延后，导致应该过期的数据又在从库上被读取到了。

1）EXPIRE和PEXPIRE：它们给数据设置的是从命令执行时开始计算的存活时间；

2）EXPIREAT和PEXPIREAT：它们会直接把数据的过期时间设置为具体的一个时间点。

为了避免这种情况，建议是：在业务应用中使用EXPIREAT、PEXPIREAT命令，把数据的过期时间设置为具体的时间点，避免读到过期数据。

3.不合理的配置项导致服务挂掉

1）protected-mode配置项

这个配置项的作用是限定哨兵实例能否被其他服务器访问。当这个配置项设置为yes时，哨兵实例只能在部署的服务器本地访问。当设置为no时，其他服务器也可以访问这个哨兵实例。

如果设置为yes，其他哨兵实例部署在其他服务器，这样哨兵实例之间就无法互相通信。当主库故障时，哨兵无法判断主库下线，也无法进行主从切换，导致Redis服务不可用。

2）cluster-node-timeout

这个配置项设置了Redis Cluster中实例响应心跳消息的超时时间。

在Redis Cluster集群中为每个实例配置了"一主一从"模式时，如果主实例发生故障，从实例就会切换为主实例，受网络延迟和切换操作执行影响，切换时间可能过长，就会导致实例的心跳超时。

所以执行主从切换的实例超过半数，而主从切换时间又过长的话，就可能有半数以上的实例超时，从而导致整个集群挂掉。所以建议调大些(10s-20s)。



## 三十二、脑裂：一次奇怪的数据丢失

1.在使用主从集群时，我们曾遇到过这样一个问题：我们的主从集群中有一个主库、5个从库和3个哨兵实例，在使用的过程中，我们发现客户端发送的一些数据丢失了，这直接影响到了业务层的可靠性。经过一系列的问题排查，我们才知道，这其实是主从集群的脑裂问题导致的。

2.所谓的脑裂，就是好指在主从集群中，同时出现了两个主节点，它们都能接受写请求。而脑裂最直接的影响，就是客户端不知道应该往哪个主节点写入数据，结果就是不同的客户端会往不同的主节点写入数据。而且，严重的话，脑裂会进一步导致数据丢失。

3.为什么会发生脑裂？

最初的发现问题，在主从集群中客户端发送的数据丢失了。所以，要搞清楚为什么数据会丢失？是不是数据同步出了问题？

1）确认是不是数据同步出现了问题？

在主从集群中发生数据丢失，最常见的原因就是主库的数据还没有同步到从库，结果主库发生了故障，等从库升级为主库后，未同步的数据就丢失了。

如果是这种情况的数据丢失，我们可以通过比对主从库上的复制进度差值来进行判断，也就是计算master_repl_offset和slave_repl_offset的差值。如果主库上的slave_repl_offset小于原主库的master_repl_offset，那么我们就可以认定为数据丢失是数据未同步完成导致的。

2）排查客户端的操作日志，发现脑裂现象

在排查客户端的操作日志时，我们发现，在主从切换后的一段时间内，有一个客户端仍然在和原主库通信，并没有和升级的新主库进行交互。这就相当于主从集群中同时有了两个主库，根据这个就分析出了一个问题：脑裂。

但是，不同客户端给两个主库发送数据写操作，按理来说，自会导致新数据会分布在不同的主库上。

3）发现是原主库假故障导致的脑裂

采用哨兵机制进行主从切换，当主从切换发生时，一定是有超过预设数量(quorum配置项)的哨兵实例和主库心跳都超时了，才会把主库判断为客观下线，然后，哨兵开始执行切换操作。哨兵切换成功后，客户端会和新主库进行通信，发送请求操作。

但是，在切换过程中，既然客户端仍和原主库通信，这就表明，原主库并没有真的发生故障(例如主库进程挂掉)。我们猜测，主库是由于某些原因无法请求，也没有办法响应哨兵的心跳，才被哨兵错误地判断为客观下线的。结果，在被判断下线之后，原主库又重新开始处理请求了，而此时，哨兵还没有完成主从切换，客户端仍然可以和原主库通信，客户端发送的写请求就会在原主库上写入数据了。

4.为什么脑裂会导致数据丢失？

主从切换后，从库一旦升级为新主库，哨兵就会让原主库执行slave of命令，和新主库重新进行全量同步，原主库需要清空本地的数据，加载新主库的数据，加载新主库发送的RDB文件，这样一来，原主库在主从切换期间保存的新写数据就丢失了。

5.如何应对脑裂问题?

问题是出在原主库发生假故障后仍然能接受请求上，我们就开始在主从集群机制的配置项中查找是否有限制主库接受请求的设置。

通过查找，Redis已经提供了两个配置项来限制主库的请求处理，分别是min-slave-to-write和min-slaves-max-lag。

1）min-slaves-to-write：这个配置项设置了主库能进行数据同步的最少从库数量；

2）min-slaves-max-lag：这个配置项设置了主从库进行数据复制时，从库给主库发送ACK消息的最大延迟(以seconds为单位)。

我们可以把这两个参数加起来搭配使用，分别设置一定的阈值。分别为N和T。在T时间内N个从库无法与主库通信，主库就不能接受处理请求了。

6.脑裂发生的原因：

1）和主库部署在同一台服务器上的其他程序占用了大量资源(例如CPU资源)，导致主库资源使用受限，短时间内无法响应心跳。其他程序不再使用资源时，主库又恢复正常。

2）主库本身遇到了阻塞问题，例如处理bigKey或者是发生内存swap，短时间内无法响应心跳，等主库阻塞接触后，又恢复正常的请求处理了。



## 三十九：Redis6.0的新特性:多线程、客户端缓存与安全

1.Redis6.0的几个关键新特性，分别是面向网络处理的多IO线程、客户端缓存、细粒度的权限控制、以及RESP3协议的使用。

2.从单线程处理网络请求到多线程处理

在Redis6.0中，非常受关注的第一个新特性就是多线程。这是因为，Redis的性能瓶颈出现在网络IO的处理上，也就是说单个主线程处理网络请求的速度跟不上底层网络硬件的速度。

为了应对这个问题，一般有两个方法。

第一种方法是，用用户态网络协议栈(例如DPDK)取代内核网络协议栈，让网络请求处理不在内核中执行，直接在用户态完成处理就行。

第二种方法就是采用多个IO线程来处理网络请求，提高网络请求处理的并行度。Redis6.0采用的就是这个方法。

3.我们可以把主线程和多IO线程的写作分成四个阶段

1）阶段一：服务端和客户端建立Socket连接，并分配处理线程

首先主线程负责接收建立连接请求。当有客户端请求和实例建立Socket连接时，主线程会创建和客户端的连接，并把Socket放入全局等待队列中。紧接着，主线程通过轮训方法把Socket连接分配给IO线程

2）阶段二：IO线程读取并解析请求

主线程一旦把Socket分配给IO线程，就会进入阻塞状态，等待IO线程完成客户端请求读取和解析。因为有多个IO线程在并行处理,所以，这个过程很快就可以完成。

3）阶段3：主线程执行请求操作

等到IO线程解析完请求，主线程还是会以单线程的方式执行这些命令操作。下面这张图显示了刚才介绍的这三个阶段。

![image-20211108191357267](pic\image-20211108191357267.png)

4）阶段四:IO线程回写Socket和主线程清空全局队列

当主线程执行完请求操作后，会把需要返回的结果写入缓冲区，然后，主线程会阻塞等待IO线程把这些结果回写到Socket中，并返回给客户端。

和IO线程读取和解析请求一样，IO线程回写Socket时，也是有多个线程在并发执行，所以回写Socket的速度也很快。等到IO线程回写Socket完毕，主线程回清空全局队列，等待客户端的后续请求。

![image-20211108192619433](pic\image-20211108192619433.png)

4.在Redis6.0中，多线程机制默认是关闭的，如果需要使用多线程功能，需要在Redis.conf中完成两个设置。

1）设置io-thread-do-reads配置项为yes，表示启用多线程。

2）设置线程个数。一般来说，线程个数要小于Redis实例所在机器的CPU核数，例如，对于一个8核的机器来说，Redis官方建议配置6个IO线程。

场景：如果在实际应用中，发现Redis实例的CPU开销不大，吞吐量没有提升，可以考虑使用Redis6.0多线程机制，加速网络处理，进而提升实例的吞吐量。

5.实现服务端协助的客户端缓存

Redis6.0新增了一个重要的特性，就是实现了服务端协助的客户端缓存功能，也称为追踪(Tracking)功能。有了和这个功能，业务应用中的Redis客户端就可以把读取的数据缓存在业务应用本地了，应用就可以直接在本地快速读取数据了。

6.0实现Tracking功能实现了两种模式，来解决这个问题。

第一种模式是普通模式。在这个模式下，实例会在服务端记录客户端读取过的key，并检测key是否有修改。一旦key的值发生变化，服务端会给客户端发送invalidate消息，通知客户端缓存失效了。

在使用普通模式时，有一点你需要注意一下，服务端对于记录的key只会报告一次invalidate消息，也就是说，服务端在给客户端发送过一次invalidate消息后，如果key再被修改，此时，服务端就不会再次给客户端发送invalidate消息。

只有当客户端再次执行读命令时，服务端才会再次再次检测被读取的key，并在key修改时发送invalidate消息。这样设计的考虑是节省有限的内存空间。毕竟，如果客户端不再访问这个key了，而服务端仍然记录key的修改情况，就会浪费内存资源。

第二种模式是广播模式。在这个模式下，服务端会给客户端广播所有key的失效情况，不过这样做了之后，如果key被频繁修改，服务端会发送大量的失效广播消息，这就耗费了大量的网络带宽资源。

6.从简单的基于密码访问到细粒度的权限控制

6.0支持支持创建不同的用户来使用Redis，6.0版本还支持以用户为粒度设置命令操作的访问权限。

7.启用RESP3协议。

